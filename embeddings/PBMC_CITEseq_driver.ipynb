{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualities = np.logspace(-3, 0, 10)\n",
    "replicates = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a5967efc254c79b0983928a2d40289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d5c22d3aa8490a8d87efc4402f61c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.442. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 500/10000 (batch 1000) - train loss: 0.0761, val loss: 0.0455\n",
      "epoch 1000/10000 (batch 2000) - train loss: 0.0173, val loss: 0.0173\n",
      "epoch 1500/10000 (batch 3000) - train loss: 0.0132, val loss: 0.0116\n",
      "epoch 2000/10000 (batch 4000) - train loss: 0.0072, val loss: 0.0176\n",
      "Early stopping triggered at epoch 2000, batch 4000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 6.800. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.054. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 12/10000 (batch 1000) - train loss: 6.0274, val loss: 5.9801\n",
      "epoch 23/10000 (batch 2000) - train loss: 4.5339, val loss: 4.5143\n",
      "epoch 34/10000 (batch 3000) - train loss: 2.2871, val loss: 2.2494\n",
      "epoch 45/10000 (batch 4000) - train loss: 0.5378, val loss: 0.5204\n",
      "epoch 56/10000 (batch 5000) - train loss: 0.1482, val loss: 0.1424\n",
      "epoch 67/10000 (batch 6000) - train loss: 0.0639, val loss: 0.0630\n",
      "epoch 78/10000 (batch 7000) - train loss: 0.0373, val loss: 0.0367\n",
      "epoch 89/10000 (batch 8000) - train loss: 0.0265, val loss: 0.0272\n",
      "epoch 100/10000 (batch 9000) - train loss: 0.0217, val loss: 0.0222\n",
      "epoch 112/10000 (batch 10000) - train loss: 0.0223, val loss: 0.0186\n",
      "epoch 123/10000 (batch 11000) - train loss: 0.0180, val loss: 0.0178\n",
      "epoch 134/10000 (batch 12000) - train loss: 0.0188, val loss: 0.0175\n",
      "epoch 145/10000 (batch 13000) - train loss: 0.0181, val loss: 0.0174\n",
      "epoch 156/10000 (batch 14000) - train loss: 0.0151, val loss: 0.0163\n",
      "epoch 167/10000 (batch 15000) - train loss: 0.0151, val loss: 0.0153\n",
      "epoch 178/10000 (batch 16000) - train loss: 0.0136, val loss: 0.0152\n",
      "epoch 189/10000 (batch 17000) - train loss: 0.0109, val loss: 0.0125\n",
      "epoch 200/10000 (batch 18000) - train loss: 0.0098, val loss: 0.0101\n",
      "epoch 212/10000 (batch 19000) - train loss: 0.0078, val loss: 0.0099\n",
      "epoch 223/10000 (batch 20000) - train loss: 0.0079, val loss: 0.0098\n",
      "epoch 234/10000 (batch 21000) - train loss: 0.0085, val loss: 0.0097\n",
      "epoch 245/10000 (batch 22000) - train loss: 0.0092, val loss: 0.0092\n",
      "epoch 256/10000 (batch 23000) - train loss: 0.0084, val loss: 0.0084\n",
      "epoch 267/10000 (batch 24000) - train loss: 0.0083, val loss: 0.0091\n",
      "Early stopping triggered at epoch 267, batch 24000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.922. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 6.293. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.8779, val loss: 6.8745\n",
      "epoch 1/10000 (batch 2000) - train loss: 6.8658, val loss: 6.8285\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.7591, val loss: 6.7527\n",
      "epoch 2/10000 (batch 4000) - train loss: 6.7103, val loss: 6.6480\n",
      "epoch 2/10000 (batch 5000) - train loss: 6.6510, val loss: 6.5133\n",
      "epoch 3/10000 (batch 6000) - train loss: 6.3746, val loss: 6.3479\n",
      "epoch 3/10000 (batch 7000) - train loss: 6.2812, val loss: 6.1533\n",
      "epoch 3/10000 (batch 8000) - train loss: 6.1781, val loss: 5.9293\n",
      "epoch 4/10000 (batch 9000) - train loss: 5.7348, val loss: 5.6754\n",
      "epoch 4/10000 (batch 10000) - train loss: 5.5975, val loss: 5.3922\n",
      "epoch 4/10000 (batch 11000) - train loss: 5.4505, val loss: 5.0788\n",
      "epoch 5/10000 (batch 12000) - train loss: 4.8415, val loss: 4.7367\n",
      "epoch 5/10000 (batch 13000) - train loss: 4.6614, val loss: 4.3660\n",
      "epoch 5/10000 (batch 14000) - train loss: 4.4720, val loss: 3.9686\n",
      "epoch 6/10000 (batch 15000) - train loss: 3.7059, val loss: 3.5461\n",
      "epoch 6/10000 (batch 16000) - train loss: 3.4881, val loss: 3.1019\n",
      "epoch 6/10000 (batch 17000) - train loss: 3.2640, val loss: 2.6420\n",
      "epoch 7/10000 (batch 18000) - train loss: 2.3851, val loss: 2.1769\n",
      "epoch 7/10000 (batch 19000) - train loss: 2.1549, val loss: 1.7247\n",
      "epoch 8/10000 (batch 20000) - train loss: 1.3132, val loss: 1.3052\n",
      "epoch 8/10000 (batch 21000) - train loss: 1.1267, val loss: 0.9432\n",
      "epoch 8/10000 (batch 22000) - train loss: 0.9634, val loss: 0.6557\n",
      "epoch 9/10000 (batch 23000) - train loss: 0.4619, val loss: 0.4442\n",
      "epoch 9/10000 (batch 24000) - train loss: 0.3815, val loss: 0.2973\n",
      "epoch 9/10000 (batch 25000) - train loss: 0.3194, val loss: 0.1996\n",
      "epoch 10/10000 (batch 26000) - train loss: 0.1451, val loss: 0.1356\n",
      "epoch 10/10000 (batch 27000) - train loss: 0.1214, val loss: 0.0940\n",
      "epoch 10/10000 (batch 28000) - train loss: 0.1035, val loss: 0.0668\n",
      "epoch 11/10000 (batch 29000) - train loss: 0.0531, val loss: 0.0493\n",
      "epoch 11/10000 (batch 30000) - train loss: 0.0465, val loss: 0.0387\n",
      "epoch 11/10000 (batch 31000) - train loss: 0.0415, val loss: 0.0314\n",
      "epoch 12/10000 (batch 32000) - train loss: 0.0276, val loss: 0.0262\n",
      "epoch 12/10000 (batch 33000) - train loss: 0.0258, val loss: 0.0233\n",
      "epoch 12/10000 (batch 34000) - train loss: 0.0245, val loss: 0.0214\n",
      "epoch 13/10000 (batch 35000) - train loss: 0.0204, val loss: 0.0202\n",
      "epoch 13/10000 (batch 36000) - train loss: 0.0201, val loss: 0.0194\n",
      "epoch 13/10000 (batch 37000) - train loss: 0.0198, val loss: 0.0191\n",
      "epoch 14/10000 (batch 38000) - train loss: 0.0187, val loss: 0.0185\n",
      "epoch 14/10000 (batch 39000) - train loss: 0.0186, val loss: 0.0179\n",
      "epoch 15/10000 (batch 40000) - train loss: 0.0187, val loss: 0.0181\n",
      "Early stopping triggered at epoch 15, batch 40000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bfedb7fde7412999ece1a4fdfa7b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 16.976. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 500/10000 (batch 1000) - train loss: 0.1177, val loss: 0.0702\n",
      "epoch 1000/10000 (batch 2000) - train loss: 0.0580, val loss: 0.0483\n",
      "epoch 1500/10000 (batch 3000) - train loss: 0.0471, val loss: 0.0607\n",
      "Early stopping triggered at epoch 1500, batch 3000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 18.115. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 20.011. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 12/10000 (batch 1000) - train loss: 6.0386, val loss: 5.9908\n",
      "epoch 23/10000 (batch 2000) - train loss: 4.5385, val loss: 4.5193\n",
      "epoch 34/10000 (batch 3000) - train loss: 2.2876, val loss: 2.2507\n",
      "epoch 45/10000 (batch 4000) - train loss: 0.5621, val loss: 0.5428\n",
      "epoch 56/10000 (batch 5000) - train loss: 0.1796, val loss: 0.1779\n",
      "epoch 67/10000 (batch 6000) - train loss: 0.1036, val loss: 0.1030\n",
      "epoch 78/10000 (batch 7000) - train loss: 0.0781, val loss: 0.0812\n",
      "epoch 89/10000 (batch 8000) - train loss: 0.0672, val loss: 0.0681\n",
      "epoch 100/10000 (batch 9000) - train loss: 0.0644, val loss: 0.0671\n",
      "epoch 112/10000 (batch 10000) - train loss: 0.0606, val loss: 0.0608\n",
      "epoch 123/10000 (batch 11000) - train loss: 0.0578, val loss: 0.0600\n",
      "epoch 134/10000 (batch 12000) - train loss: 0.0538, val loss: 0.0549\n",
      "epoch 145/10000 (batch 13000) - train loss: 0.0542, val loss: 0.0527\n",
      "epoch 156/10000 (batch 14000) - train loss: 0.0467, val loss: 0.0487\n",
      "epoch 167/10000 (batch 15000) - train loss: 0.0433, val loss: 0.0455\n",
      "epoch 178/10000 (batch 16000) - train loss: 0.0413, val loss: 0.0391\n",
      "epoch 189/10000 (batch 17000) - train loss: 0.0387, val loss: 0.0397\n",
      "Early stopping triggered at epoch 189, batch 17000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 21.695. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 23.219. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.7366, val loss: 6.7214\n",
      "epoch 1/10000 (batch 2000) - train loss: 6.7187, val loss: 6.6754\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.6066, val loss: 6.6000\n",
      "epoch 2/10000 (batch 4000) - train loss: 6.5573, val loss: 6.4947\n",
      "epoch 2/10000 (batch 5000) - train loss: 6.4982, val loss: 6.3605\n",
      "epoch 3/10000 (batch 6000) - train loss: 6.2225, val loss: 6.1959\n",
      "epoch 3/10000 (batch 7000) - train loss: 6.1291, val loss: 6.0019\n",
      "epoch 3/10000 (batch 8000) - train loss: 6.0261, val loss: 5.7778\n",
      "epoch 4/10000 (batch 9000) - train loss: 5.5834, val loss: 5.5242\n",
      "epoch 4/10000 (batch 10000) - train loss: 5.4463, val loss: 5.2408\n",
      "epoch 4/10000 (batch 11000) - train loss: 5.2995, val loss: 4.9288\n",
      "epoch 5/10000 (batch 12000) - train loss: 4.6919, val loss: 4.5873\n",
      "epoch 5/10000 (batch 13000) - train loss: 4.5121, val loss: 4.2174\n",
      "epoch 5/10000 (batch 14000) - train loss: 4.3233, val loss: 3.8213\n",
      "epoch 6/10000 (batch 15000) - train loss: 3.5603, val loss: 3.4011\n",
      "epoch 6/10000 (batch 16000) - train loss: 3.3440, val loss: 2.9608\n",
      "epoch 6/10000 (batch 17000) - train loss: 3.1222, val loss: 2.5071\n",
      "epoch 7/10000 (batch 18000) - train loss: 2.2554, val loss: 2.0523\n",
      "epoch 7/10000 (batch 19000) - train loss: 2.0318, val loss: 1.6150\n",
      "epoch 8/10000 (batch 20000) - train loss: 1.2255, val loss: 1.2174\n",
      "epoch 8/10000 (batch 21000) - train loss: 1.0512, val loss: 0.8816\n",
      "epoch 8/10000 (batch 22000) - train loss: 0.9010, val loss: 0.6200\n",
      "epoch 9/10000 (batch 23000) - train loss: 0.4458, val loss: 0.4309\n",
      "epoch 9/10000 (batch 24000) - train loss: 0.3760, val loss: 0.3020\n",
      "epoch 9/10000 (batch 25000) - train loss: 0.3219, val loss: 0.2158\n",
      "epoch 10/10000 (batch 26000) - train loss: 0.1685, val loss: 0.1602\n",
      "epoch 10/10000 (batch 27000) - train loss: 0.1488, val loss: 0.1252\n",
      "epoch 10/10000 (batch 28000) - train loss: 0.1338, val loss: 0.1018\n",
      "epoch 11/10000 (batch 29000) - train loss: 0.0902, val loss: 0.0871\n",
      "epoch 11/10000 (batch 30000) - train loss: 0.0854, val loss: 0.0776\n",
      "epoch 11/10000 (batch 31000) - train loss: 0.0813, val loss: 0.0716\n",
      "epoch 12/10000 (batch 32000) - train loss: 0.0694, val loss: 0.0683\n",
      "epoch 12/10000 (batch 33000) - train loss: 0.0684, val loss: 0.0661\n",
      "epoch 12/10000 (batch 34000) - train loss: 0.0673, val loss: 0.0639\n",
      "epoch 13/10000 (batch 35000) - train loss: 0.0640, val loss: 0.0634\n",
      "epoch 13/10000 (batch 36000) - train loss: 0.0642, val loss: 0.0631\n",
      "epoch 13/10000 (batch 37000) - train loss: 0.0638, val loss: 0.0636\n",
      "Early stopping triggered at epoch 13, batch 37000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6288e71e215d4624a44222f0f486cf7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 44.653. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 500/10000 (batch 1000) - train loss: 0.2062, val loss: 0.2286\n",
      "epoch 1000/10000 (batch 2000) - train loss: 0.1687, val loss: 0.1297\n",
      "epoch 1500/10000 (batch 3000) - train loss: 0.1339, val loss: 0.1196\n",
      "epoch 2000/10000 (batch 4000) - train loss: 0.0895, val loss: 0.1263\n",
      "Early stopping triggered at epoch 2000, batch 4000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 50.716. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 54.998. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 12/10000 (batch 1000) - train loss: 6.0492, val loss: 6.0069\n",
      "epoch 23/10000 (batch 2000) - train loss: 4.5661, val loss: 4.5484\n",
      "epoch 34/10000 (batch 3000) - train loss: 2.3392, val loss: 2.3068\n",
      "epoch 45/10000 (batch 4000) - train loss: 0.6431, val loss: 0.6407\n",
      "epoch 56/10000 (batch 5000) - train loss: 0.2859, val loss: 0.2956\n",
      "epoch 67/10000 (batch 6000) - train loss: 0.2148, val loss: 0.2273\n",
      "epoch 78/10000 (batch 7000) - train loss: 0.1938, val loss: 0.1983\n",
      "epoch 89/10000 (batch 8000) - train loss: 0.1809, val loss: 0.1930\n",
      "epoch 100/10000 (batch 9000) - train loss: 0.1761, val loss: 0.1891\n",
      "epoch 112/10000 (batch 10000) - train loss: 0.1822, val loss: 0.1756\n",
      "epoch 123/10000 (batch 11000) - train loss: 0.1625, val loss: 0.1749\n",
      "epoch 134/10000 (batch 12000) - train loss: 0.1563, val loss: 0.1681\n",
      "epoch 145/10000 (batch 13000) - train loss: 0.1421, val loss: 0.1505\n",
      "epoch 156/10000 (batch 14000) - train loss: 0.1299, val loss: 0.1443\n",
      "epoch 167/10000 (batch 15000) - train loss: 0.1193, val loss: 0.1377\n",
      "epoch 178/10000 (batch 16000) - train loss: 0.1160, val loss: 0.1275\n",
      "epoch 189/10000 (batch 17000) - train loss: 0.1179, val loss: 0.1288\n",
      "Early stopping triggered at epoch 189, batch 17000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=394` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 5.7536, val loss: 5.6865\n",
      "epoch 1/10000 (batch 2000) - train loss: 5.7102, val loss: 5.6424\n",
      "epoch 2/10000 (batch 3000) - train loss: 5.5763, val loss: 5.5702\n",
      "epoch 2/10000 (batch 4000) - train loss: 5.5296, val loss: 5.4700\n",
      "epoch 2/10000 (batch 5000) - train loss: 5.4732, val loss: 5.3416\n",
      "epoch 3/10000 (batch 6000) - train loss: 5.2094, val loss: 5.1845\n",
      "epoch 3/10000 (batch 7000) - train loss: 5.1204, val loss: 4.9985\n",
      "epoch 3/10000 (batch 8000) - train loss: 5.0220, val loss: 4.7855\n",
      "epoch 4/10000 (batch 9000) - train loss: 4.5993, val loss: 4.5438\n",
      "epoch 4/10000 (batch 10000) - train loss: 4.4699, val loss: 4.2749\n",
      "epoch 4/10000 (batch 11000) - train loss: 4.3306, val loss: 3.9790\n",
      "epoch 5/10000 (batch 12000) - train loss: 3.7568, val loss: 3.6575\n",
      "epoch 5/10000 (batch 13000) - train loss: 3.5879, val loss: 3.3127\n",
      "epoch 5/10000 (batch 14000) - train loss: 3.4119, val loss: 2.9462\n",
      "epoch 6/10000 (batch 15000) - train loss: 2.7093, val loss: 2.5652\n",
      "epoch 6/10000 (batch 16000) - train loss: 2.5159, val loss: 2.1773\n",
      "epoch 6/10000 (batch 17000) - train loss: 2.3221, val loss: 1.7937\n",
      "epoch 7/10000 (batch 18000) - train loss: 1.5909, val loss: 1.4310\n",
      "epoch 7/10000 (batch 19000) - train loss: 1.4191, val loss: 1.1079\n",
      "epoch 8/10000 (batch 20000) - train loss: 0.8463, val loss: 0.8401\n",
      "epoch 8/10000 (batch 21000) - train loss: 0.7359, val loss: 0.6332\n",
      "epoch 8/10000 (batch 22000) - train loss: 0.6474, val loss: 0.4829\n",
      "epoch 9/10000 (batch 23000) - train loss: 0.3841, val loss: 0.3796\n",
      "epoch 9/10000 (batch 24000) - train loss: 0.3476, val loss: 0.3094\n",
      "epoch 9/10000 (batch 25000) - train loss: 0.3195, val loss: 0.2640\n",
      "epoch 10/10000 (batch 26000) - train loss: 0.2387, val loss: 0.2324\n",
      "epoch 10/10000 (batch 27000) - train loss: 0.2270, val loss: 0.2139\n",
      "epoch 10/10000 (batch 28000) - train loss: 0.2192, val loss: 0.2020\n",
      "epoch 11/10000 (batch 29000) - train loss: 0.1986, val loss: 0.1942\n",
      "epoch 11/10000 (batch 30000) - train loss: 0.1947, val loss: 0.1895\n",
      "epoch 11/10000 (batch 31000) - train loss: 0.1922, val loss: 0.1868\n",
      "epoch 12/10000 (batch 32000) - train loss: 0.1841, val loss: 0.1846\n",
      "epoch 12/10000 (batch 33000) - train loss: 0.1838, val loss: 0.1823\n",
      "epoch 12/10000 (batch 34000) - train loss: 0.1828, val loss: 0.1810\n",
      "epoch 13/10000 (batch 35000) - train loss: 0.1802, val loss: 0.1800\n",
      "epoch 13/10000 (batch 36000) - train loss: 0.1798, val loss: 0.1793\n",
      "epoch 13/10000 (batch 37000) - train loss: 0.1797, val loss: 0.1777\n",
      "epoch 14/10000 (batch 38000) - train loss: 0.1777, val loss: 0.1787\n",
      "Early stopping triggered at epoch 14, batch 38000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b862b6881a0e4459b6bfc7471ee8068b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 135.026. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 500/10000 (batch 1000) - train loss: 0.5221, val loss: 0.4968\n",
      "epoch 1000/10000 (batch 2000) - train loss: 0.3780, val loss: 0.3748\n",
      "epoch 1500/10000 (batch 3000) - train loss: 0.3395, val loss: 0.3196\n",
      "epoch 2000/10000 (batch 4000) - train loss: 0.2966, val loss: 0.3195\n",
      "epoch 2500/10000 (batch 5000) - train loss: 0.3641, val loss: 0.2927\n",
      "epoch 3000/10000 (batch 6000) - train loss: 0.2724, val loss: 0.3076\n",
      "Early stopping triggered at epoch 3000, batch 6000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 141.211. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 12/10000 (batch 1000) - train loss: 7.0987, val loss: 7.1110\n",
      "epoch 23/10000 (batch 2000) - train loss: 5.7459, val loss: 5.7280\n",
      "epoch 34/10000 (batch 3000) - train loss: 3.5429, val loss: 3.5037\n",
      "epoch 45/10000 (batch 4000) - train loss: 1.2658, val loss: 1.2322\n",
      "epoch 56/10000 (batch 5000) - train loss: 0.6401, val loss: 0.6184\n",
      "epoch 67/10000 (batch 6000) - train loss: 0.5381, val loss: 0.5305\n",
      "epoch 78/10000 (batch 7000) - train loss: 0.5039, val loss: 0.5009\n",
      "epoch 89/10000 (batch 8000) - train loss: 0.4925, val loss: 0.4898\n",
      "epoch 100/10000 (batch 9000) - train loss: 0.4694, val loss: 0.4779\n",
      "epoch 112/10000 (batch 10000) - train loss: 0.4596, val loss: 0.4651\n",
      "epoch 123/10000 (batch 11000) - train loss: 0.4678, val loss: 0.4439\n",
      "epoch 134/10000 (batch 12000) - train loss: 0.4054, val loss: 0.4222\n",
      "epoch 145/10000 (batch 13000) - train loss: 0.3943, val loss: 0.3953\n",
      "epoch 156/10000 (batch 14000) - train loss: 0.3811, val loss: 0.3740\n",
      "epoch 167/10000 (batch 15000) - train loss: 0.3620, val loss: 0.3602\n",
      "epoch 178/10000 (batch 16000) - train loss: 0.3613, val loss: 0.3659\n",
      "Early stopping triggered at epoch 178, batch 16000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=394` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 5.9192, val loss: 5.8617\n",
      "epoch 1/10000 (batch 2000) - train loss: 5.8805, val loss: 5.8181\n",
      "epoch 2/10000 (batch 3000) - train loss: 5.7535, val loss: 5.7472\n",
      "epoch 2/10000 (batch 4000) - train loss: 5.7066, val loss: 5.6483\n",
      "epoch 2/10000 (batch 5000) - train loss: 5.6512, val loss: 5.5228\n",
      "epoch 3/10000 (batch 6000) - train loss: 5.3923, val loss: 5.3681\n",
      "epoch 3/10000 (batch 7000) - train loss: 5.3048, val loss: 5.1855\n",
      "epoch 3/10000 (batch 8000) - train loss: 5.2081, val loss: 4.9766\n",
      "epoch 4/10000 (batch 9000) - train loss: 4.7944, val loss: 4.7391\n",
      "epoch 4/10000 (batch 10000) - train loss: 4.6665, val loss: 4.4753\n",
      "epoch 4/10000 (batch 11000) - train loss: 4.5293, val loss: 4.1847\n",
      "epoch 5/10000 (batch 12000) - train loss: 3.9663, val loss: 3.8700\n",
      "epoch 5/10000 (batch 13000) - train loss: 3.7986, val loss: 3.5300\n",
      "epoch 5/10000 (batch 14000) - train loss: 3.6263, val loss: 3.1711\n",
      "epoch 6/10000 (batch 15000) - train loss: 2.9337, val loss: 2.7946\n",
      "epoch 6/10000 (batch 16000) - train loss: 2.7443, val loss: 2.4110\n",
      "epoch 6/10000 (batch 17000) - train loss: 2.5531, val loss: 2.0318\n",
      "epoch 7/10000 (batch 18000) - train loss: 1.8316, val loss: 1.6766\n",
      "epoch 7/10000 (batch 19000) - train loss: 1.6619, val loss: 1.3584\n",
      "epoch 8/10000 (batch 20000) - train loss: 1.0976, val loss: 1.0940\n",
      "epoch 8/10000 (batch 21000) - train loss: 0.9898, val loss: 0.8937\n",
      "epoch 8/10000 (batch 22000) - train loss: 0.9048, val loss: 0.7511\n",
      "epoch 9/10000 (batch 23000) - train loss: 0.6567, val loss: 0.6547\n",
      "epoch 9/10000 (batch 24000) - train loss: 0.6255, val loss: 0.5916\n",
      "epoch 9/10000 (batch 25000) - train loss: 0.5985, val loss: 0.5526\n",
      "epoch 10/10000 (batch 26000) - train loss: 0.5302, val loss: 0.5282\n",
      "epoch 10/10000 (batch 27000) - train loss: 0.5220, val loss: 0.5138\n",
      "epoch 10/10000 (batch 28000) - train loss: 0.5138, val loss: 0.5033\n",
      "epoch 11/10000 (batch 29000) - train loss: 0.4975, val loss: 0.4971\n",
      "epoch 11/10000 (batch 30000) - train loss: 0.4933, val loss: 0.4920\n",
      "epoch 11/10000 (batch 31000) - train loss: 0.4912, val loss: 0.4904\n",
      "epoch 12/10000 (batch 32000) - train loss: 0.4855, val loss: 0.4849\n",
      "epoch 12/10000 (batch 33000) - train loss: 0.4814, val loss: 0.4836\n",
      "epoch 12/10000 (batch 34000) - train loss: 0.4813, val loss: 0.4821\n",
      "epoch 13/10000 (batch 35000) - train loss: 0.4770, val loss: 0.4790\n",
      "epoch 13/10000 (batch 36000) - train loss: 0.4756, val loss: 0.4761\n",
      "epoch 13/10000 (batch 37000) - train loss: 0.4745, val loss: 0.4766\n",
      "Early stopping triggered at epoch 13, batch 37000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaa79a966dc4906b31783c8078adbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 297.211. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 500/10000 (batch 1000) - train loss: 0.9953, val loss: 0.7092\n",
      "epoch 1000/10000 (batch 2000) - train loss: 0.8647, val loss: 0.6229\n",
      "epoch 1500/10000 (batch 3000) - train loss: 0.7954, val loss: 0.5353\n",
      "epoch 2000/10000 (batch 4000) - train loss: 0.7549, val loss: 0.5993\n",
      "Early stopping triggered at epoch 2000, batch 4000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 266.256. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 12/10000 (batch 1000) - train loss: 5.5419, val loss: 5.4807\n",
      "epoch 23/10000 (batch 2000) - train loss: 4.2273, val loss: 4.2383\n",
      "epoch 34/10000 (batch 3000) - train loss: 2.4069, val loss: 2.4058\n",
      "epoch 45/10000 (batch 4000) - train loss: 1.2520, val loss: 1.2669\n",
      "epoch 56/10000 (batch 5000) - train loss: 1.0197, val loss: 1.0571\n",
      "epoch 67/10000 (batch 6000) - train loss: 0.9566, val loss: 1.0224\n",
      "epoch 78/10000 (batch 7000) - train loss: 0.9446, val loss: 0.9861\n",
      "epoch 89/10000 (batch 8000) - train loss: 0.9367, val loss: 0.9760\n",
      "epoch 100/10000 (batch 9000) - train loss: 0.9079, val loss: 0.9450\n",
      "epoch 112/10000 (batch 10000) - train loss: 0.8721, val loss: 0.9049\n",
      "epoch 123/10000 (batch 11000) - train loss: 0.8409, val loss: 0.8819\n",
      "epoch 134/10000 (batch 12000) - train loss: 0.7904, val loss: 0.8389\n",
      "epoch 145/10000 (batch 13000) - train loss: 0.7882, val loss: 0.8136\n",
      "epoch 156/10000 (batch 14000) - train loss: 0.7552, val loss: 0.7883\n",
      "epoch 167/10000 (batch 15000) - train loss: 0.7560, val loss: 0.7836\n",
      "epoch 178/10000 (batch 16000) - train loss: 0.7351, val loss: 0.7800\n",
      "epoch 189/10000 (batch 17000) - train loss: 0.7485, val loss: 0.7728\n",
      "epoch 200/10000 (batch 18000) - train loss: 0.7348, val loss: 0.7579\n",
      "epoch 212/10000 (batch 19000) - train loss: 0.7648, val loss: 0.7642\n",
      "Early stopping triggered at epoch 212, batch 19000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=394` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=70` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.6758, val loss: 6.6606\n",
      "epoch 1/10000 (batch 2000) - train loss: 6.6592, val loss: 6.6202\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.5595, val loss: 6.5537\n",
      "epoch 2/10000 (batch 4000) - train loss: 6.5165, val loss: 6.4617\n",
      "epoch 2/10000 (batch 5000) - train loss: 6.4643, val loss: 6.3435\n",
      "epoch 3/10000 (batch 6000) - train loss: 6.2213, val loss: 6.1981\n",
      "epoch 3/10000 (batch 7000) - train loss: 6.1402, val loss: 6.0281\n",
      "epoch 3/10000 (batch 8000) - train loss: 6.0498, val loss: 5.8317\n",
      "epoch 4/10000 (batch 9000) - train loss: 5.6615, val loss: 5.6094\n",
      "epoch 4/10000 (batch 10000) - train loss: 5.5412, val loss: 5.3616\n",
      "epoch 4/10000 (batch 11000) - train loss: 5.4133, val loss: 5.0885\n",
      "epoch 5/10000 (batch 12000) - train loss: 4.8816, val loss: 4.7891\n",
      "epoch 5/10000 (batch 13000) - train loss: 4.7232, val loss: 4.4655\n",
      "epoch 5/10000 (batch 14000) - train loss: 4.5589, val loss: 4.1198\n",
      "epoch 6/10000 (batch 15000) - train loss: 3.8928, val loss: 3.7529\n",
      "epoch 6/10000 (batch 16000) - train loss: 3.7036, val loss: 3.3682\n",
      "epoch 6/10000 (batch 17000) - train loss: 3.5103, val loss: 2.9737\n",
      "epoch 7/10000 (batch 18000) - train loss: 2.7532, val loss: 2.5795\n",
      "epoch 7/10000 (batch 19000) - train loss: 2.5615, val loss: 2.2008\n",
      "epoch 8/10000 (batch 20000) - train loss: 1.8637, val loss: 1.8597\n",
      "epoch 8/10000 (batch 21000) - train loss: 1.7175, val loss: 1.5766\n",
      "epoch 8/10000 (batch 22000) - train loss: 1.5930, val loss: 1.3589\n",
      "epoch 9/10000 (batch 23000) - train loss: 1.2288, val loss: 1.2083\n",
      "epoch 9/10000 (batch 24000) - train loss: 1.1687, val loss: 1.1123\n",
      "epoch 9/10000 (batch 25000) - train loss: 1.1284, val loss: 1.0516\n",
      "epoch 10/10000 (batch 26000) - train loss: 1.0201, val loss: 1.0156\n",
      "epoch 10/10000 (batch 27000) - train loss: 1.0125, val loss: 0.9939\n",
      "epoch 10/10000 (batch 28000) - train loss: 1.0016, val loss: 0.9819\n",
      "epoch 11/10000 (batch 29000) - train loss: 0.9730, val loss: 0.9718\n",
      "epoch 11/10000 (batch 30000) - train loss: 0.9733, val loss: 0.9658\n",
      "epoch 11/10000 (batch 31000) - train loss: 0.9688, val loss: 0.9618\n",
      "epoch 12/10000 (batch 32000) - train loss: 0.9619, val loss: 0.9541\n",
      "epoch 12/10000 (batch 33000) - train loss: 0.9548, val loss: 0.9525\n",
      "epoch 12/10000 (batch 34000) - train loss: 0.9536, val loss: 0.9448\n",
      "epoch 13/10000 (batch 35000) - train loss: 0.9467, val loss: 0.9438\n",
      "epoch 13/10000 (batch 36000) - train loss: 0.9459, val loss: 0.9409\n",
      "epoch 13/10000 (batch 37000) - train loss: 0.9440, val loss: 0.9367\n",
      "epoch 14/10000 (batch 38000) - train loss: 0.9357, val loss: 0.9323\n",
      "epoch 14/10000 (batch 39000) - train loss: 0.9349, val loss: 0.9297\n",
      "epoch 15/10000 (batch 40000) - train loss: 0.9424, val loss: 0.9264\n",
      "epoch 15/10000 (batch 41000) - train loss: 0.9319, val loss: 0.9229\n",
      "epoch 15/10000 (batch 42000) - train loss: 0.9252, val loss: 0.9189\n",
      "epoch 16/10000 (batch 43000) - train loss: 0.9129, val loss: 0.9153\n",
      "epoch 16/10000 (batch 44000) - train loss: 0.9128, val loss: 0.9104\n",
      "epoch 16/10000 (batch 45000) - train loss: 0.9114, val loss: 0.9064\n",
      "epoch 17/10000 (batch 46000) - train loss: 0.9059, val loss: 0.9000\n",
      "epoch 17/10000 (batch 47000) - train loss: 0.8998, val loss: 0.8958\n",
      "epoch 17/10000 (batch 48000) - train loss: 0.8973, val loss: 0.8907\n",
      "epoch 18/10000 (batch 49000) - train loss: 0.8873, val loss: 0.8818\n",
      "epoch 18/10000 (batch 50000) - train loss: 0.8849, val loss: 0.8772\n",
      "epoch 18/10000 (batch 51000) - train loss: 0.8806, val loss: 0.8722\n",
      "epoch 19/10000 (batch 52000) - train loss: 0.8754, val loss: 0.8650\n",
      "epoch 19/10000 (batch 53000) - train loss: 0.8663, val loss: 0.8606\n",
      "epoch 19/10000 (batch 54000) - train loss: 0.8630, val loss: 0.8538\n",
      "epoch 20/10000 (batch 55000) - train loss: 0.8500, val loss: 0.8457\n",
      "epoch 20/10000 (batch 56000) - train loss: 0.8458, val loss: 0.8404\n",
      "epoch 20/10000 (batch 57000) - train loss: 0.8433, val loss: 0.8335\n",
      "epoch 21/10000 (batch 58000) - train loss: 0.8323, val loss: 0.8272\n",
      "epoch 21/10000 (batch 59000) - train loss: 0.8278, val loss: 0.8187\n",
      "epoch 22/10000 (batch 60000) - train loss: 0.8217, val loss: 0.8151\n",
      "epoch 22/10000 (batch 61000) - train loss: 0.8124, val loss: 0.8066\n",
      "epoch 22/10000 (batch 62000) - train loss: 0.8095, val loss: 0.8030\n",
      "epoch 23/10000 (batch 63000) - train loss: 0.7929, val loss: 0.7944\n",
      "epoch 23/10000 (batch 64000) - train loss: 0.7920, val loss: 0.7901\n",
      "epoch 23/10000 (batch 65000) - train loss: 0.7900, val loss: 0.7873\n",
      "epoch 24/10000 (batch 66000) - train loss: 0.7826, val loss: 0.7819\n",
      "epoch 24/10000 (batch 67000) - train loss: 0.7817, val loss: 0.7769\n",
      "epoch 24/10000 (batch 68000) - train loss: 0.7786, val loss: 0.7712\n",
      "epoch 25/10000 (batch 69000) - train loss: 0.7665, val loss: 0.7685\n",
      "epoch 25/10000 (batch 70000) - train loss: 0.7692, val loss: 0.7642\n",
      "epoch 25/10000 (batch 71000) - train loss: 0.7692, val loss: 0.7633\n",
      "epoch 26/10000 (batch 72000) - train loss: 0.7618, val loss: 0.7578\n",
      "epoch 26/10000 (batch 73000) - train loss: 0.7587, val loss: 0.7560\n",
      "epoch 26/10000 (batch 74000) - train loss: 0.7590, val loss: 0.7537\n",
      "epoch 27/10000 (batch 75000) - train loss: 0.7565, val loss: 0.7512\n",
      "epoch 27/10000 (batch 76000) - train loss: 0.7528, val loss: 0.7482\n",
      "epoch 28/10000 (batch 77000) - train loss: 0.7483, val loss: 0.7470\n",
      "epoch 28/10000 (batch 78000) - train loss: 0.7458, val loss: 0.7480\n",
      "Early stopping triggered at epoch 28, batch 78000\n",
      "embedding generation completed! :) \n"
     ]
    }
   ],
   "source": [
    "for q in tqdm(qualities[::2]):\n",
    "    for r in tqdm(range(replicates), leave=False):\n",
    "        # with io.capture_output() as captured:\n",
    "        !python PBMC_CITEseq_embedding_generation.py {q} {r} 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
