{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualities = np.logspace(-3, 0, 10)\n",
    "replicates = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e996942895ba44c9a2e126fdbaf2ecf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36b139413ae43338ce1090dcfae85cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 1.252. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.1877, val loss: 0.1219\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.0268, val loss: 0.0154\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.0090, val loss: 0.0063\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.0141, val loss: 0.0034\n",
      "epoch 5000/10000 (batch 5000) - train loss: 0.0022, val loss: 0.0092\n",
      "Early stopping triggered at epoch 5000, batch 5000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.687. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.826. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.475. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 6.1640, val loss: 6.1247\n",
      "epoch 125/10000 (batch 2000) - train loss: 3.9684, val loss: 3.9443\n",
      "epoch 188/10000 (batch 3000) - train loss: 0.9957, val loss: 0.9866\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.1527, val loss: 0.1521\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.0474, val loss: 0.0476\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.0223, val loss: 0.0233\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.0134, val loss: 0.0130\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.0088, val loss: 0.0075\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.0065, val loss: 0.0043\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.0058, val loss: 0.0076\n",
      "Early stopping triggered at epoch 625, batch 10000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.171. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.320. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.151. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.6611, val loss: 6.6553\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.4486, val loss: 6.4425\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.1077, val loss: 6.0937\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.6329, val loss: 5.6082\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.0237, val loss: 4.9855\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.2813, val loss: 4.2267\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.4132, val loss: 3.3408\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.3701, val loss: 2.3633\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.4279, val loss: 1.4127\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.7185, val loss: 0.7028\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.3362, val loss: 0.3253\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.1624, val loss: 0.1573\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.0843, val loss: 0.0816\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.0471, val loss: 0.0450\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.0298, val loss: 0.0267\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.0154, val loss: 0.0171\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.0110, val loss: 0.0113\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.0085, val loss: 0.0090\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.0078, val loss: 0.0077\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.0075, val loss: 0.0076\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.0068, val loss: 0.0063\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.0063, val loss: 0.0057\n",
      "epoch 142/10000 (batch 23000) - train loss: 0.0072, val loss: 0.0059\n",
      "Early stopping triggered at epoch 142, batch 23000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.225. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.164. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 2.350. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 7.1531, val loss: 7.1678\n",
      "epoch 2/10000 (batch 2000) - train loss: 7.1510, val loss: 7.1463\n",
      "epoch 2/10000 (batch 3000) - train loss: 7.1356, val loss: 7.1119\n",
      "epoch 3/10000 (batch 4000) - train loss: 7.0819, val loss: 7.0633\n",
      "epoch 4/10000 (batch 5000) - train loss: 7.0041, val loss: 7.0011\n",
      "epoch 4/10000 (batch 6000) - train loss: 6.9675, val loss: 6.9251\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.8570, val loss: 6.8359\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.8074, val loss: 6.7319\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.6642, val loss: 6.6152\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.4966, val loss: 6.4839\n",
      "epoch 7/10000 (batch 11000) - train loss: 6.4260, val loss: 6.3395\n",
      "epoch 8/10000 (batch 12000) - train loss: 6.2257, val loss: 6.1811\n",
      "epoch 8/10000 (batch 13000) - train loss: 6.1420, val loss: 6.0087\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.9091, val loss: 5.8230\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.6517, val loss: 5.6232\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.5468, val loss: 5.4100\n",
      "epoch 11/10000 (batch 17000) - train loss: 5.2568, val loss: 5.1828\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.9426, val loss: 4.9421\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.8164, val loss: 4.6871\n",
      "epoch 13/10000 (batch 20000) - train loss: 4.4700, val loss: 4.4196\n",
      "epoch 13/10000 (batch 21000) - train loss: 4.3314, val loss: 4.1387\n",
      "epoch 14/10000 (batch 22000) - train loss: 3.9539, val loss: 3.8454\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.5544, val loss: 3.5392\n",
      "epoch 15/10000 (batch 24000) - train loss: 3.3972, val loss: 3.2231\n",
      "epoch 16/10000 (batch 25000) - train loss: 2.9731, val loss: 2.8976\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.8080, val loss: 2.5655\n",
      "epoch 17/10000 (batch 27000) - train loss: 2.3693, val loss: 2.2314\n",
      "epoch 18/10000 (batch 28000) - train loss: 1.9314, val loss: 1.9006\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.7697, val loss: 1.5802\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.3604, val loss: 1.2795\n",
      "epoch 19/10000 (batch 31000) - train loss: 1.2189, val loss: 1.0075\n",
      "epoch 20/10000 (batch 32000) - train loss: 0.8768, val loss: 0.7728\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.6036, val loss: 0.5787\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.5217, val loss: 0.4252\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.3425, val loss: 0.3079\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.2213, val loss: 0.2207\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.1877, val loss: 0.1575\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.1194, val loss: 0.1117\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.1016, val loss: 0.0801\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.0648, val loss: 0.0570\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.0418, val loss: 0.0411\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.0358, val loss: 0.0299\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.0236, val loss: 0.0220\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.0208, val loss: 0.0170\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.0149, val loss: 0.0133\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.0113, val loss: 0.0107\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.0103, val loss: 0.0094\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.0083, val loss: 0.0082\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.0079, val loss: 0.0074\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.0072, val loss: 0.0074\n",
      "Early stopping triggered at epoch 31, batch 50000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26839a34b90d4117b22a2841ee38c779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 4.693. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.1680, val loss: 0.1203\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.0286, val loss: 0.0155\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.0221, val loss: 0.0068\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.0104, val loss: 0.0113\n",
      "Early stopping triggered at epoch 4000, batch 4000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 7.080. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 6.587. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.380. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 7.9872, val loss: 8.0477\n",
      "epoch 125/10000 (batch 2000) - train loss: 5.9674, val loss: 5.9431\n",
      "epoch 188/10000 (batch 3000) - train loss: 2.4411, val loss: 2.4234\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.2741, val loss: 0.2676\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.0689, val loss: 0.0705\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.0324, val loss: 0.0341\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.0195, val loss: 0.0194\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.0152, val loss: 0.0146\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.0109, val loss: 0.0164\n",
      "Early stopping triggered at epoch 563, batch 9000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 6.321. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.362. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.445. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 7.0484, val loss: 7.0603\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.8551, val loss: 6.8489\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.5151, val loss: 6.5012\n",
      "epoch 25/10000 (batch 4000) - train loss: 6.0401, val loss: 6.0155\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.4281, val loss: 5.3898\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.6775, val loss: 4.6224\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.7919, val loss: 3.7177\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.7057, val loss: 2.6985\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.6797, val loss: 1.6616\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.8557, val loss: 0.8362\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.3944, val loss: 0.3826\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.1894, val loss: 0.1821\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.0987, val loss: 0.0960\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.0574, val loss: 0.0567\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.0303, val loss: 0.0350\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.0255, val loss: 0.0227\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.0191, val loss: 0.0188\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.0169, val loss: 0.0174\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.0148, val loss: 0.0156\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.0142, val loss: 0.0145\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.0141, val loss: 0.0137\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.0138, val loss: 0.0151\n",
      "Early stopping triggered at epoch 135, batch 22000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.325. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.370. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 5.500. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.7306, val loss: 6.7172\n",
      "epoch 2/10000 (batch 2000) - train loss: 6.7004, val loss: 6.6956\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.6847, val loss: 6.6602\n",
      "epoch 3/10000 (batch 4000) - train loss: 6.6301, val loss: 6.6110\n",
      "epoch 4/10000 (batch 5000) - train loss: 6.5509, val loss: 6.5476\n",
      "epoch 4/10000 (batch 6000) - train loss: 6.5136, val loss: 6.4705\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.4012, val loss: 6.3790\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.3507, val loss: 6.2739\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.2049, val loss: 6.1546\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.0342, val loss: 6.0214\n",
      "epoch 7/10000 (batch 11000) - train loss: 5.9623, val loss: 5.8743\n",
      "epoch 8/10000 (batch 12000) - train loss: 5.7584, val loss: 5.7129\n",
      "epoch 8/10000 (batch 13000) - train loss: 5.6733, val loss: 5.5378\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.4363, val loss: 5.3484\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.1747, val loss: 5.1456\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.0681, val loss: 4.9290\n",
      "epoch 11/10000 (batch 17000) - train loss: 4.7736, val loss: 4.6988\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.4551, val loss: 4.4540\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.3270, val loss: 4.1965\n",
      "epoch 13/10000 (batch 20000) - train loss: 3.9766, val loss: 3.9259\n",
      "epoch 13/10000 (batch 21000) - train loss: 3.8368, val loss: 3.6428\n",
      "epoch 14/10000 (batch 22000) - train loss: 3.4571, val loss: 3.3481\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.0584, val loss: 3.0432\n",
      "epoch 15/10000 (batch 24000) - train loss: 2.9026, val loss: 2.7303\n",
      "epoch 16/10000 (batch 25000) - train loss: 2.4857, val loss: 2.4127\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.3262, val loss: 2.0937\n",
      "epoch 17/10000 (batch 27000) - train loss: 1.9080, val loss: 1.7793\n",
      "epoch 18/10000 (batch 28000) - train loss: 1.5049, val loss: 1.4770\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.3612, val loss: 1.1955\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.0096, val loss: 0.9426\n",
      "epoch 19/10000 (batch 31000) - train loss: 0.8945, val loss: 0.7257\n",
      "epoch 20/10000 (batch 32000) - train loss: 0.6249, val loss: 0.5464\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.4224, val loss: 0.4044\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.3643, val loss: 0.2966\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.2392, val loss: 0.2157\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.1548, val loss: 0.1565\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.1343, val loss: 0.1142\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.0895, val loss: 0.0837\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.0770, val loss: 0.0623\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.0517, val loss: 0.0467\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.0370, val loss: 0.0368\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.0331, val loss: 0.0295\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.0255, val loss: 0.0249\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.0236, val loss: 0.0215\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.0195, val loss: 0.0186\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.0176, val loss: 0.0177\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.0168, val loss: 0.0167\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.0159, val loss: 0.0154\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.0154, val loss: 0.0153\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.0156, val loss: 0.0155\n",
      "Early stopping triggered at epoch 31, batch 50000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0462077828364b01a5fd758d2971148c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 9.393. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.1748, val loss: 0.1261\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.0589, val loss: 0.0395\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.0367, val loss: 0.0598\n",
      "Early stopping triggered at epoch 3000, batch 3000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 9.790. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 11.646. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 11.463. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 6.2034, val loss: 6.1660\n",
      "epoch 125/10000 (batch 2000) - train loss: 4.0317, val loss: 4.0043\n",
      "epoch 188/10000 (batch 3000) - train loss: 1.0208, val loss: 1.0095\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.1698, val loss: 0.1672\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.0676, val loss: 0.0739\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.0447, val loss: 0.0396\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.0379, val loss: 0.0310\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.0326, val loss: 0.0317\n",
      "Early stopping triggered at epoch 500, batch 8000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 11.666. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 12.598. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 13.696. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.9054, val loss: 6.9144\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.7090, val loss: 6.7029\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.3701, val loss: 6.3569\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.8986, val loss: 5.8741\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.2937, val loss: 5.2561\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.5563, val loss: 4.5030\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.6904, val loss: 3.6181\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.6363, val loss: 2.6293\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.6474, val loss: 1.6308\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.8576, val loss: 0.8398\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.4099, val loss: 0.3991\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.2080, val loss: 0.2047\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.1183, val loss: 0.1145\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.0772, val loss: 0.0770\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.0389, val loss: 0.0560\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.0405, val loss: 0.0470\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.0400, val loss: 0.0374\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.0377, val loss: 0.0388\n",
      "Early stopping triggered at epoch 111, batch 18000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 12.633. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 13.010. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 12.803. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 5.8821, val loss: 5.8232\n",
      "epoch 2/10000 (batch 2000) - train loss: 5.8062, val loss: 5.8015\n",
      "epoch 2/10000 (batch 3000) - train loss: 5.7905, val loss: 5.7660\n",
      "epoch 3/10000 (batch 4000) - train loss: 5.7357, val loss: 5.7163\n",
      "epoch 4/10000 (batch 5000) - train loss: 5.6562, val loss: 5.6529\n",
      "epoch 4/10000 (batch 6000) - train loss: 5.6187, val loss: 5.5750\n",
      "epoch 5/10000 (batch 7000) - train loss: 5.5056, val loss: 5.4833\n",
      "epoch 5/10000 (batch 8000) - train loss: 5.4549, val loss: 5.3776\n",
      "epoch 6/10000 (batch 9000) - train loss: 5.3084, val loss: 5.2578\n",
      "epoch 7/10000 (batch 10000) - train loss: 5.1365, val loss: 5.1235\n",
      "epoch 7/10000 (batch 11000) - train loss: 5.0644, val loss: 4.9753\n",
      "epoch 8/10000 (batch 12000) - train loss: 4.8592, val loss: 4.8132\n",
      "epoch 8/10000 (batch 13000) - train loss: 4.7736, val loss: 4.6374\n",
      "epoch 9/10000 (batch 14000) - train loss: 4.5355, val loss: 4.4470\n",
      "epoch 10/10000 (batch 15000) - train loss: 4.2731, val loss: 4.2436\n",
      "epoch 10/10000 (batch 16000) - train loss: 4.1658, val loss: 4.0260\n",
      "epoch 11/10000 (batch 17000) - train loss: 3.8705, val loss: 3.7955\n",
      "epoch 12/10000 (batch 18000) - train loss: 3.5536, val loss: 3.5519\n",
      "epoch 12/10000 (batch 19000) - train loss: 3.4255, val loss: 3.2958\n",
      "epoch 13/10000 (batch 20000) - train loss: 3.0791, val loss: 3.0293\n",
      "epoch 13/10000 (batch 21000) - train loss: 2.9421, val loss: 2.7526\n",
      "epoch 14/10000 (batch 22000) - train loss: 2.5733, val loss: 2.4686\n",
      "epoch 15/10000 (batch 23000) - train loss: 2.1947, val loss: 2.1803\n",
      "epoch 15/10000 (batch 24000) - train loss: 2.0503, val loss: 1.8923\n",
      "epoch 16/10000 (batch 25000) - train loss: 1.6746, val loss: 1.6099\n",
      "epoch 16/10000 (batch 26000) - train loss: 1.5368, val loss: 1.3401\n",
      "epoch 17/10000 (batch 27000) - train loss: 1.1901, val loss: 1.0892\n",
      "epoch 18/10000 (batch 28000) - train loss: 0.8851, val loss: 0.8658\n",
      "epoch 18/10000 (batch 29000) - train loss: 0.7858, val loss: 0.6739\n",
      "epoch 19/10000 (batch 30000) - train loss: 0.5567, val loss: 0.5155\n",
      "epoch 19/10000 (batch 31000) - train loss: 0.4881, val loss: 0.3898\n",
      "epoch 20/10000 (batch 32000) - train loss: 0.3348, val loss: 0.2928\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.2283, val loss: 0.2196\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.1998, val loss: 0.1658\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.1386, val loss: 0.1269\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.1009, val loss: 0.0990\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.0882, val loss: 0.0787\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.0675, val loss: 0.0644\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.0617, val loss: 0.0544\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.0508, val loss: 0.0485\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.0445, val loss: 0.0437\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.0428, val loss: 0.0407\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.0392, val loss: 0.0389\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.0385, val loss: 0.0370\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.0371, val loss: 0.0363\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.0361, val loss: 0.0356\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.0357, val loss: 0.0351\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.0361, val loss: 0.0347\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.0359, val loss: 0.0350\n",
      "Early stopping triggered at epoch 30, batch 49000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a13a32821554462abc562e963b9c87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 13.616. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.2273, val loss: 0.1390\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.0657, val loss: 0.0563\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.0485, val loss: 0.0533\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.0412, val loss: 0.0464\n",
      "epoch 5000/10000 (batch 5000) - train loss: 0.0399, val loss: 0.0328\n",
      "epoch 6000/10000 (batch 6000) - train loss: 0.0423, val loss: 0.0318\n",
      "epoch 7000/10000 (batch 7000) - train loss: 0.0281, val loss: 0.0435\n",
      "Early stopping triggered at epoch 7000, batch 7000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 17.295. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 19.353. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 19.042. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 6.8467, val loss: 6.8448\n",
      "epoch 125/10000 (batch 2000) - train loss: 4.7178, val loss: 4.6903\n",
      "epoch 188/10000 (batch 3000) - train loss: 1.4462, val loss: 1.4327\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.2243, val loss: 0.2125\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.1029, val loss: 0.0896\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.0713, val loss: 0.0593\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.0583, val loss: 0.0531\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.0471, val loss: 0.0533\n",
      "Early stopping triggered at epoch 500, batch 8000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 19.305. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 20.941. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 18.869. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 7.1092, val loss: 7.1237\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.9187, val loss: 6.9124\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.5801, val loss: 6.5666\n",
      "epoch 25/10000 (batch 4000) - train loss: 6.1078, val loss: 6.0841\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.4999, val loss: 5.4625\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.7560, val loss: 4.7012\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.8775, val loss: 3.8032\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.7965, val loss: 2.7906\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.7693, val loss: 1.7491\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.9269, val loss: 0.9064\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.4461, val loss: 0.4356\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.2333, val loss: 0.2261\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.1420, val loss: 0.1349\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.0987, val loss: 0.0979\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.0722, val loss: 0.0770\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.0664, val loss: 0.0679\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.0590, val loss: 0.0611\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.0577, val loss: 0.0583\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.0558, val loss: 0.0570\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.0524, val loss: 0.0518\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.0536, val loss: 0.0535\n",
      "Early stopping triggered at epoch 129, batch 21000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 19.389. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 19.961. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 20.035. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.7002, val loss: 6.6913\n",
      "epoch 2/10000 (batch 2000) - train loss: 6.6748, val loss: 6.6699\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.6591, val loss: 6.6347\n",
      "epoch 3/10000 (batch 4000) - train loss: 6.6045, val loss: 6.5853\n",
      "epoch 4/10000 (batch 5000) - train loss: 6.5253, val loss: 6.5220\n",
      "epoch 4/10000 (batch 6000) - train loss: 6.4881, val loss: 6.4449\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.3755, val loss: 6.3536\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.3251, val loss: 6.2483\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.1793, val loss: 6.1290\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.0084, val loss: 5.9958\n",
      "epoch 7/10000 (batch 11000) - train loss: 5.9364, val loss: 5.8481\n",
      "epoch 8/10000 (batch 12000) - train loss: 5.7323, val loss: 5.6868\n",
      "epoch 8/10000 (batch 13000) - train loss: 5.6472, val loss: 5.5114\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.4099, val loss: 5.3223\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.1478, val loss: 5.1188\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.0412, val loss: 4.9021\n",
      "epoch 11/10000 (batch 17000) - train loss: 4.7467, val loss: 4.6713\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.4270, val loss: 4.4269\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.2999, val loss: 4.1692\n",
      "epoch 13/10000 (batch 20000) - train loss: 3.9497, val loss: 3.8990\n",
      "epoch 13/10000 (batch 21000) - train loss: 3.8101, val loss: 3.6160\n",
      "epoch 14/10000 (batch 22000) - train loss: 3.4304, val loss: 3.3215\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.0315, val loss: 3.0176\n",
      "epoch 15/10000 (batch 24000) - train loss: 2.8771, val loss: 2.7059\n",
      "epoch 16/10000 (batch 25000) - train loss: 2.4623, val loss: 2.3888\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.3034, val loss: 2.0715\n",
      "epoch 17/10000 (batch 27000) - train loss: 1.8879, val loss: 1.7598\n",
      "epoch 18/10000 (batch 28000) - train loss: 1.4903, val loss: 1.4613\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.3483, val loss: 1.1851\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.0035, val loss: 0.9381\n",
      "epoch 19/10000 (batch 31000) - train loss: 0.8922, val loss: 0.7282\n",
      "epoch 20/10000 (batch 32000) - train loss: 0.6317, val loss: 0.5560\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.4370, val loss: 0.4203\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.3822, val loss: 0.3174\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.2642, val loss: 0.2419\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.1913, val loss: 0.1870\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.1653, val loss: 0.1466\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.1232, val loss: 0.1192\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.1128, val loss: 0.1001\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.0907, val loss: 0.0859\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.0764, val loss: 0.0764\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.0740, val loss: 0.0701\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.0672, val loss: 0.0659\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.0650, val loss: 0.0620\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.0626, val loss: 0.0604\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.0596, val loss: 0.0589\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.0596, val loss: 0.0596\n",
      "Early stopping triggered at epoch 29, batch 47000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581b93aa78a4475b94f8fd5cb46ad5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 28.130. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.3162, val loss: 0.2270\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.1238, val loss: 0.0916\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.0973, val loss: 0.0810\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.0810, val loss: 0.0633\n",
      "epoch 5000/10000 (batch 5000) - train loss: 0.0669, val loss: 0.0628\n",
      "epoch 6000/10000 (batch 6000) - train loss: 0.0585, val loss: 0.0522\n",
      "epoch 7000/10000 (batch 7000) - train loss: 0.0841, val loss: 0.0550\n",
      "Early stopping triggered at epoch 7000, batch 7000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 31.688. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 32.418. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 38.860. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 5.9421, val loss: 5.8934\n",
      "epoch 125/10000 (batch 2000) - train loss: 3.7898, val loss: 3.7692\n",
      "epoch 188/10000 (batch 3000) - train loss: 0.9814, val loss: 0.9726\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.2317, val loss: 0.2483\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.1331, val loss: 0.1391\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.1193, val loss: 0.1169\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.1071, val loss: 0.1056\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.0903, val loss: 0.0900\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.0814, val loss: 0.0741\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.0686, val loss: 0.0789\n",
      "Early stopping triggered at epoch 625, batch 10000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 27.942. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 31.809. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 33.921. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.7390, val loss: 6.7371\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.5304, val loss: 6.5238\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.1884, val loss: 6.1743\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.7115, val loss: 5.6866\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.0977, val loss: 5.0590\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.3476, val loss: 4.2929\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.4685, val loss: 3.3938\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.4077, val loss: 2.4055\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.4637, val loss: 1.4463\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.7687, val loss: 0.7523\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.4052, val loss: 0.3968\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.2460, val loss: 0.2395\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.1738, val loss: 0.1700\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.1433, val loss: 0.1413\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.1291, val loss: 0.1226\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.1099, val loss: 0.1143\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.1071, val loss: 0.1096\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.1052, val loss: 0.1055\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.1046, val loss: 0.1053\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.0999, val loss: 0.1002\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.0986, val loss: 0.0979\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.0913, val loss: 0.0909\n",
      "epoch 142/10000 (batch 23000) - train loss: 0.0873, val loss: 0.0852\n",
      "epoch 148/10000 (batch 24000) - train loss: 0.0791, val loss: 0.0801\n",
      "epoch 154/10000 (batch 25000) - train loss: 0.0780, val loss: 0.0760\n",
      "epoch 160/10000 (batch 26000) - train loss: 0.0701, val loss: 0.0675\n",
      "epoch 166/10000 (batch 27000) - train loss: 0.0680, val loss: 0.0697\n",
      "Early stopping triggered at epoch 166, batch 27000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 35.837. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 36.736. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 36.455. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 7.1889, val loss: 7.2033\n",
      "epoch 2/10000 (batch 2000) - train loss: 7.1867, val loss: 7.1821\n",
      "epoch 2/10000 (batch 3000) - train loss: 7.1715, val loss: 7.1479\n",
      "epoch 3/10000 (batch 4000) - train loss: 7.1183, val loss: 7.0995\n",
      "epoch 4/10000 (batch 5000) - train loss: 7.0411, val loss: 7.0378\n",
      "epoch 4/10000 (batch 6000) - train loss: 7.0048, val loss: 6.9625\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.8950, val loss: 6.8733\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.8458, val loss: 6.7708\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.7035, val loss: 6.6545\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.5369, val loss: 6.5243\n",
      "epoch 7/10000 (batch 11000) - train loss: 6.4666, val loss: 6.3804\n",
      "epoch 8/10000 (batch 12000) - train loss: 6.2672, val loss: 6.2230\n",
      "epoch 8/10000 (batch 13000) - train loss: 6.1840, val loss: 6.0513\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.9519, val loss: 5.8664\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.6954, val loss: 5.6671\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.5909, val loss: 5.4546\n",
      "epoch 11/10000 (batch 17000) - train loss: 5.3017, val loss: 5.2281\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.9866, val loss: 4.9876\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.8625, val loss: 4.7334\n",
      "epoch 13/10000 (batch 20000) - train loss: 4.5169, val loss: 4.4665\n",
      "epoch 13/10000 (batch 21000) - train loss: 4.3781, val loss: 4.1865\n",
      "epoch 14/10000 (batch 22000) - train loss: 4.0009, val loss: 3.8921\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.6014, val loss: 3.5867\n",
      "epoch 15/10000 (batch 24000) - train loss: 3.4443, val loss: 3.2702\n",
      "epoch 16/10000 (batch 25000) - train loss: 3.0203, val loss: 2.9440\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.8552, val loss: 2.6119\n",
      "epoch 17/10000 (batch 27000) - train loss: 2.4156, val loss: 2.2775\n",
      "epoch 18/10000 (batch 28000) - train loss: 1.9779, val loss: 1.9468\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.8160, val loss: 1.6265\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.4085, val loss: 1.3285\n",
      "epoch 19/10000 (batch 31000) - train loss: 1.2684, val loss: 1.0593\n",
      "epoch 20/10000 (batch 32000) - train loss: 0.9309, val loss: 0.8281\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.6624, val loss: 0.6398\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.5846, val loss: 0.4930\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.4131, val loss: 0.3806\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.3015, val loss: 0.2992\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.2682, val loss: 0.2407\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.2067, val loss: 0.1996\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.1892, val loss: 0.1687\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.1562, val loss: 0.1502\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.1342, val loss: 0.1370\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.1318, val loss: 0.1272\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.1233, val loss: 0.1208\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.1199, val loss: 0.1174\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.1145, val loss: 0.1144\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.1126, val loss: 0.1129\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.1105, val loss: 0.1113\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.1093, val loss: 0.1094\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.1082, val loss: 0.1073\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.1065, val loss: 0.1071\n",
      "epoch 32/10000 (batch 51000) - train loss: 0.1059, val loss: 0.1047\n",
      "epoch 32/10000 (batch 52000) - train loss: 0.1054, val loss: 0.1039\n",
      "epoch 33/10000 (batch 53000) - train loss: 0.1036, val loss: 0.1034\n",
      "epoch 34/10000 (batch 54000) - train loss: 0.1088, val loss: 0.1022\n",
      "epoch 34/10000 (batch 55000) - train loss: 0.1019, val loss: 0.1015\n",
      "epoch 35/10000 (batch 56000) - train loss: 0.0999, val loss: 0.0996\n",
      "epoch 35/10000 (batch 57000) - train loss: 0.0996, val loss: 0.0994\n",
      "epoch 36/10000 (batch 58000) - train loss: 0.0978, val loss: 0.0968\n",
      "epoch 37/10000 (batch 59000) - train loss: 0.0923, val loss: 0.0959\n",
      "epoch 37/10000 (batch 60000) - train loss: 0.0947, val loss: 0.0950\n",
      "epoch 38/10000 (batch 61000) - train loss: 0.0937, val loss: 0.0924\n",
      "epoch 38/10000 (batch 62000) - train loss: 0.0922, val loss: 0.0905\n",
      "epoch 39/10000 (batch 63000) - train loss: 0.0904, val loss: 0.0886\n",
      "epoch 40/10000 (batch 64000) - train loss: 0.0875, val loss: 0.0879\n",
      "epoch 40/10000 (batch 65000) - train loss: 0.0870, val loss: 0.0874\n",
      "epoch 41/10000 (batch 66000) - train loss: 0.0849, val loss: 0.0842\n",
      "epoch 41/10000 (batch 67000) - train loss: 0.0840, val loss: 0.0826\n",
      "epoch 42/10000 (batch 68000) - train loss: 0.0798, val loss: 0.0814\n",
      "epoch 43/10000 (batch 69000) - train loss: 0.0791, val loss: 0.0788\n",
      "epoch 43/10000 (batch 70000) - train loss: 0.0786, val loss: 0.0765\n",
      "epoch 44/10000 (batch 71000) - train loss: 0.0747, val loss: 0.0758\n",
      "epoch 45/10000 (batch 72000) - train loss: 0.0765, val loss: 0.0732\n",
      "epoch 45/10000 (batch 73000) - train loss: 0.0721, val loss: 0.0716\n",
      "epoch 46/10000 (batch 74000) - train loss: 0.0703, val loss: 0.0705\n",
      "epoch 46/10000 (batch 75000) - train loss: 0.0699, val loss: 0.0690\n",
      "epoch 47/10000 (batch 76000) - train loss: 0.0683, val loss: 0.0681\n",
      "epoch 48/10000 (batch 77000) - train loss: 0.0661, val loss: 0.0671\n",
      "epoch 48/10000 (batch 78000) - train loss: 0.0668, val loss: 0.0665\n",
      "epoch 49/10000 (batch 79000) - train loss: 0.0671, val loss: 0.0661\n",
      "epoch 49/10000 (batch 80000) - train loss: 0.0654, val loss: 0.0650\n",
      "epoch 50/10000 (batch 81000) - train loss: 0.0656, val loss: 0.0656\n",
      "Early stopping triggered at epoch 50, batch 81000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877970e82def458f84073d5d37af58db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 49.255. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.4070, val loss: 0.3205\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.2262, val loss: 0.1938\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.1248, val loss: 0.1715\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.1491, val loss: 0.1471\n",
      "epoch 5000/10000 (batch 5000) - train loss: 0.1227, val loss: 0.1313\n",
      "epoch 6000/10000 (batch 6000) - train loss: 0.1312, val loss: 0.1552\n",
      "Early stopping triggered at epoch 6000, batch 6000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 64.805. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 63.415. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 58.144. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 6.6867, val loss: 6.6781\n",
      "epoch 125/10000 (batch 2000) - train loss: 4.5548, val loss: 4.5309\n",
      "epoch 188/10000 (batch 3000) - train loss: 1.3714, val loss: 1.3749\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.3479, val loss: 0.3351\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.2380, val loss: 0.2281\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.1993, val loss: 0.1888\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.1920, val loss: 0.1803\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.1696, val loss: 0.1632\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.1398, val loss: 0.1226\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.1322, val loss: 0.1322\n",
      "Early stopping triggered at epoch 625, batch 10000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 57.462. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 58.500. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 61.316. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.8508, val loss: 6.8516\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.6531, val loss: 6.6467\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.3262, val loss: 6.3125\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.8696, val loss: 5.8463\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.2851, val loss: 5.2482\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.5703, val loss: 4.5180\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.7295, val loss: 3.6605\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.7037, val loss: 2.7023\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.7513, val loss: 1.7367\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.9902, val loss: 0.9705\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.5616, val loss: 0.5403\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.3659, val loss: 0.3547\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.2820, val loss: 0.2832\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.2420, val loss: 0.2363\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.2257, val loss: 0.2190\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.2035, val loss: 0.2067\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.2018, val loss: 0.1999\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.1986, val loss: 0.1935\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.1908, val loss: 0.1911\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.1880, val loss: 0.1822\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.1760, val loss: 0.1719\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.1689, val loss: 0.1657\n",
      "epoch 142/10000 (batch 23000) - train loss: 0.1616, val loss: 0.1524\n",
      "epoch 148/10000 (batch 24000) - train loss: 0.1467, val loss: 0.1475\n",
      "epoch 154/10000 (batch 25000) - train loss: 0.1378, val loss: 0.1380\n",
      "epoch 160/10000 (batch 26000) - train loss: 0.1366, val loss: 0.1306\n",
      "epoch 166/10000 (batch 27000) - train loss: 0.1329, val loss: 0.1271\n",
      "epoch 172/10000 (batch 28000) - train loss: 0.1287, val loss: 0.1275\n",
      "Early stopping triggered at epoch 172, batch 28000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 60.691. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 63.351. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 65.774. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 7.1761, val loss: 7.1951\n",
      "epoch 2/10000 (batch 2000) - train loss: 7.1791, val loss: 7.1748\n",
      "epoch 2/10000 (batch 3000) - train loss: 7.1646, val loss: 7.1418\n",
      "epoch 3/10000 (batch 4000) - train loss: 7.1136, val loss: 7.0950\n",
      "epoch 4/10000 (batch 5000) - train loss: 7.0397, val loss: 7.0367\n",
      "epoch 4/10000 (batch 6000) - train loss: 7.0046, val loss: 6.9641\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.8995, val loss: 6.8790\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.8522, val loss: 6.7802\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.7159, val loss: 6.6688\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.5562, val loss: 6.5443\n",
      "epoch 7/10000 (batch 11000) - train loss: 6.4887, val loss: 6.4066\n",
      "epoch 8/10000 (batch 12000) - train loss: 6.2975, val loss: 6.2555\n",
      "epoch 8/10000 (batch 13000) - train loss: 6.2178, val loss: 6.0912\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.9955, val loss: 5.9135\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.7497, val loss: 5.7226\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.6491, val loss: 5.5185\n",
      "epoch 11/10000 (batch 17000) - train loss: 5.3715, val loss: 5.3009\n",
      "epoch 12/10000 (batch 18000) - train loss: 5.0732, val loss: 5.0695\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.9487, val loss: 4.8245\n",
      "epoch 13/10000 (batch 20000) - train loss: 4.6152, val loss: 4.5677\n",
      "epoch 13/10000 (batch 21000) - train loss: 4.4818, val loss: 4.2965\n",
      "epoch 14/10000 (batch 22000) - train loss: 4.1167, val loss: 4.0123\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.7317, val loss: 3.7164\n",
      "epoch 15/10000 (batch 24000) - train loss: 3.5784, val loss: 3.4095\n",
      "epoch 16/10000 (batch 25000) - train loss: 3.1659, val loss: 3.0927\n",
      "epoch 16/10000 (batch 26000) - train loss: 3.0052, val loss: 2.7686\n",
      "epoch 17/10000 (batch 27000) - train loss: 2.5766, val loss: 2.4414\n",
      "epoch 18/10000 (batch 28000) - train loss: 2.1445, val loss: 2.1146\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.9846, val loss: 1.7963\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.5777, val loss: 1.4960\n",
      "epoch 19/10000 (batch 31000) - train loss: 1.4338, val loss: 1.2205\n",
      "epoch 20/10000 (batch 32000) - train loss: 1.0870, val loss: 0.9818\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.8074, val loss: 0.7827\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.7220, val loss: 0.6245\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.5385, val loss: 0.5033\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.4213, val loss: 0.4147\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.3791, val loss: 0.3491\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.3107, val loss: 0.3050\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.2925, val loss: 0.2723\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.2560, val loss: 0.2493\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.2342, val loss: 0.2354\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.2288, val loss: 0.2249\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.2172, val loss: 0.2168\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.2148, val loss: 0.2125\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.2101, val loss: 0.2098\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.2070, val loss: 0.2077\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.2048, val loss: 0.2047\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.1998, val loss: 0.1996\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.1994, val loss: 0.1989\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.1966, val loss: 0.1974\n",
      "epoch 32/10000 (batch 51000) - train loss: 0.1948, val loss: 0.1942\n",
      "epoch 32/10000 (batch 52000) - train loss: 0.1931, val loss: 0.1942\n",
      "epoch 33/10000 (batch 53000) - train loss: 0.1909, val loss: 0.1923\n",
      "epoch 34/10000 (batch 54000) - train loss: 0.1786, val loss: 0.1889\n",
      "epoch 34/10000 (batch 55000) - train loss: 0.1883, val loss: 0.1868\n",
      "epoch 35/10000 (batch 56000) - train loss: 0.1834, val loss: 0.1848\n",
      "epoch 35/10000 (batch 57000) - train loss: 0.1820, val loss: 0.1801\n",
      "epoch 36/10000 (batch 58000) - train loss: 0.1782, val loss: 0.1779\n",
      "epoch 37/10000 (batch 59000) - train loss: 0.1718, val loss: 0.1764\n",
      "epoch 37/10000 (batch 60000) - train loss: 0.1741, val loss: 0.1738\n",
      "epoch 38/10000 (batch 61000) - train loss: 0.1708, val loss: 0.1710\n",
      "epoch 38/10000 (batch 62000) - train loss: 0.1693, val loss: 0.1665\n",
      "epoch 39/10000 (batch 63000) - train loss: 0.1637, val loss: 0.1628\n",
      "epoch 40/10000 (batch 64000) - train loss: 0.1618, val loss: 0.1601\n",
      "epoch 40/10000 (batch 65000) - train loss: 0.1579, val loss: 0.1578\n",
      "epoch 41/10000 (batch 66000) - train loss: 0.1549, val loss: 0.1530\n",
      "epoch 41/10000 (batch 67000) - train loss: 0.1526, val loss: 0.1519\n",
      "epoch 42/10000 (batch 68000) - train loss: 0.1489, val loss: 0.1483\n",
      "epoch 43/10000 (batch 69000) - train loss: 0.1453, val loss: 0.1444\n",
      "epoch 43/10000 (batch 70000) - train loss: 0.1437, val loss: 0.1431\n",
      "epoch 44/10000 (batch 71000) - train loss: 0.1409, val loss: 0.1409\n",
      "epoch 45/10000 (batch 72000) - train loss: 0.1359, val loss: 0.1374\n",
      "epoch 45/10000 (batch 73000) - train loss: 0.1368, val loss: 0.1369\n",
      "epoch 46/10000 (batch 74000) - train loss: 0.1334, val loss: 0.1352\n",
      "epoch 46/10000 (batch 75000) - train loss: 0.1333, val loss: 0.1338\n",
      "epoch 47/10000 (batch 76000) - train loss: 0.1327, val loss: 0.1316\n",
      "epoch 48/10000 (batch 77000) - train loss: 0.1320, val loss: 0.1300\n",
      "epoch 48/10000 (batch 78000) - train loss: 0.1297, val loss: 0.1305\n",
      "Early stopping triggered at epoch 48, batch 78000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f04e009dd8444f5b3b2cb8749080bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 91.894. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.4666, val loss: 0.4817\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.3796, val loss: 0.3573\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.2401, val loss: 0.2995\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.2646, val loss: 0.2819\n",
      "epoch 5000/10000 (batch 5000) - train loss: 0.2852, val loss: 0.2879\n",
      "Early stopping triggered at epoch 5000, batch 5000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 103.329. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 123.475. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 101.434. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 5.4860, val loss: 5.4150\n",
      "epoch 125/10000 (batch 2000) - train loss: 3.3254, val loss: 3.3127\n",
      "epoch 188/10000 (batch 3000) - train loss: 0.9041, val loss: 0.9511\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.4390, val loss: 0.4794\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.3613, val loss: 0.3954\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.3262, val loss: 0.3734\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.2981, val loss: 0.3210\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.2654, val loss: 0.3129\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.2497, val loss: 0.2668\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.2341, val loss: 0.2521\n",
      "epoch 688/10000 (batch 11000) - train loss: 0.2325, val loss: 0.2514\n",
      "epoch 750/10000 (batch 12000) - train loss: 0.2285, val loss: 0.2539\n",
      "Early stopping triggered at epoch 750, batch 12000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 97.290. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 97.748. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.6264, val loss: 6.6166\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.4148, val loss: 6.4092\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.0809, val loss: 6.0673\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.6180, val loss: 5.5924\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.0209, val loss: 4.9841\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.2958, val loss: 4.2418\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.4465, val loss: 3.3763\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.4365, val loss: 2.4284\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.5581, val loss: 1.5446\n",
      "epoch 62/10000 (batch 10000) - train loss: 0.9311, val loss: 0.9187\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.6198, val loss: 0.6108\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.4838, val loss: 0.4719\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.4187, val loss: 0.4146\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.3922, val loss: 0.3871\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.3813, val loss: 0.3703\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.3721, val loss: 0.3567\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.3510, val loss: 0.3583\n",
      "Early stopping triggered at epoch 105, batch 17000\n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=263` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "/home/gokul/.local/lib/python3.10/site-packages/scvi/model/_utils.py:286: UserWarning: This dataset has some empty cells, this might fail inference.Data should be filtered with `scanpy.pp.filter_cells()`\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=122` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.8380, val loss: 6.8335\n",
      "epoch 2/10000 (batch 2000) - train loss: 6.8183, val loss: 6.8136\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.8038, val loss: 6.7814\n",
      "epoch 3/10000 (batch 4000) - train loss: 6.7538, val loss: 6.7362\n",
      "epoch 4/10000 (batch 5000) - train loss: 6.6815, val loss: 6.6787\n",
      "epoch 4/10000 (batch 6000) - train loss: 6.6475, val loss: 6.6077\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.5446, val loss: 6.5248\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.4987, val loss: 6.4285\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.3658, val loss: 6.3203\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.2101, val loss: 6.1981\n",
      "epoch 7/10000 (batch 11000) - train loss: 6.1447, val loss: 6.0642\n",
      "epoch 8/10000 (batch 12000) - train loss: 5.9590, val loss: 5.9172\n",
      "epoch 8/10000 (batch 13000) - train loss: 5.8815, val loss: 5.7585\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.6662, val loss: 5.5862\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.4284, val loss: 5.4017\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.3314, val loss: 5.2047\n",
      "epoch 11/10000 (batch 17000) - train loss: 5.0638, val loss: 4.9958\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.7737, val loss: 4.7736\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.6588, val loss: 4.5406\n",
      "epoch 13/10000 (batch 20000) - train loss: 4.3410, val loss: 4.2936\n",
      "epoch 13/10000 (batch 21000) - train loss: 4.2131, val loss: 4.0368\n",
      "epoch 14/10000 (batch 22000) - train loss: 3.8669, val loss: 3.7689\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.5036, val loss: 3.4878\n",
      "epoch 15/10000 (batch 24000) - train loss: 3.3588, val loss: 3.2004\n",
      "epoch 16/10000 (batch 25000) - train loss: 2.9726, val loss: 2.9055\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.8235, val loss: 2.6039\n",
      "epoch 17/10000 (batch 27000) - train loss: 2.4286, val loss: 2.3057\n",
      "epoch 18/10000 (batch 28000) - train loss: 2.0374, val loss: 2.0091\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.8941, val loss: 1.7251\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.5305, val loss: 1.4590\n",
      "epoch 19/10000 (batch 31000) - train loss: 1.4071, val loss: 1.2214\n",
      "epoch 20/10000 (batch 32000) - train loss: 1.1090, val loss: 1.0170\n",
      "epoch 21/10000 (batch 33000) - train loss: 0.8730, val loss: 0.8511\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.8023, val loss: 0.7188\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.6481, val loss: 0.6184\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.5597, val loss: 0.5462\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.5163, val loss: 0.4904\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.4624, val loss: 0.4553\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.4455, val loss: 0.4258\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.4161, val loss: 0.4111\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.3995, val loss: 0.3950\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.3920, val loss: 0.3906\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.3844, val loss: 0.3811\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.3790, val loss: 0.3745\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.3753, val loss: 0.3715\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.3727, val loss: 0.3658\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.3661, val loss: 0.3598\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.3608, val loss: 0.3577\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.3602, val loss: 0.3551\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.3539, val loss: 0.3515\n",
      "epoch 32/10000 (batch 51000) - train loss: 0.3497, val loss: 0.3481\n",
      "epoch 32/10000 (batch 52000) - train loss: 0.3477, val loss: 0.3444\n",
      "epoch 33/10000 (batch 53000) - train loss: 0.3410, val loss: 0.3412\n",
      "epoch 34/10000 (batch 54000) - train loss: 0.3340, val loss: 0.3378\n",
      "epoch 34/10000 (batch 55000) - train loss: 0.3354, val loss: 0.3330\n",
      "epoch 35/10000 (batch 56000) - train loss: 0.3314, val loss: 0.3274\n",
      "epoch 35/10000 (batch 57000) - train loss: 0.3276, val loss: 0.3227\n",
      "epoch 36/10000 (batch 58000) - train loss: 0.3220, val loss: 0.3194\n",
      "epoch 37/10000 (batch 59000) - train loss: 0.3210, val loss: 0.3127\n",
      "epoch 37/10000 (batch 60000) - train loss: 0.3127, val loss: 0.3062\n",
      "epoch 38/10000 (batch 61000) - train loss: 0.3081, val loss: 0.3047\n",
      "epoch 38/10000 (batch 62000) - train loss: 0.3033, val loss: 0.2973\n",
      "epoch 39/10000 (batch 63000) - train loss: 0.2946, val loss: 0.2940\n",
      "epoch 40/10000 (batch 64000) - train loss: 0.2853, val loss: 0.2885\n",
      "epoch 40/10000 (batch 65000) - train loss: 0.2870, val loss: 0.2829\n",
      "epoch 41/10000 (batch 66000) - train loss: 0.2825, val loss: 0.2798\n",
      "epoch 41/10000 (batch 67000) - train loss: 0.2784, val loss: 0.2752\n",
      "epoch 42/10000 (batch 68000) - train loss: 0.2727, val loss: 0.2710\n",
      "epoch 43/10000 (batch 69000) - train loss: 0.2676, val loss: 0.2667\n",
      "epoch 43/10000 (batch 70000) - train loss: 0.2655, val loss: 0.2643\n",
      "epoch 44/10000 (batch 71000) - train loss: 0.2627, val loss: 0.2615\n",
      "epoch 45/10000 (batch 72000) - train loss: 0.2596, val loss: 0.2582\n",
      "epoch 45/10000 (batch 73000) - train loss: 0.2577, val loss: 0.2562\n",
      "epoch 46/10000 (batch 74000) - train loss: 0.2534, val loss: 0.2540\n",
      "epoch 46/10000 (batch 75000) - train loss: 0.2526, val loss: 0.2520\n",
      "epoch 47/10000 (batch 76000) - train loss: 0.2506, val loss: 0.2496\n",
      "epoch 48/10000 (batch 77000) - train loss: 0.2457, val loss: 0.2484\n",
      "epoch 48/10000 (batch 78000) - train loss: 0.2474, val loss: 0.2469\n",
      "epoch 49/10000 (batch 79000) - train loss: 0.2473, val loss: 0.2484\n",
      "Early stopping triggered at epoch 49, batch 79000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246155836036497db94dae365b30cd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 160.237. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 0.7679, val loss: 0.6464\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.5069, val loss: 0.4628\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.4850, val loss: 0.4979\n",
      "Early stopping triggered at epoch 3000, batch 3000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 177.861. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 161.427. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 165.864. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 5.7472, val loss: 5.6791\n",
      "epoch 125/10000 (batch 2000) - train loss: 3.7730, val loss: 3.7594\n",
      "epoch 188/10000 (batch 3000) - train loss: 1.3159, val loss: 1.3060\n",
      "epoch 250/10000 (batch 4000) - train loss: 0.7171, val loss: 0.7350\n",
      "epoch 313/10000 (batch 5000) - train loss: 0.6024, val loss: 0.6323\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.5833, val loss: 0.5871\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.5220, val loss: 0.5501\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.4775, val loss: 0.4689\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.4406, val loss: 0.4571\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.4397, val loss: 0.4631\n",
      "Early stopping triggered at epoch 625, batch 10000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 177.438. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.4485, val loss: 6.4325\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.2399, val loss: 6.2321\n",
      "epoch 19/10000 (batch 3000) - train loss: 5.9209, val loss: 5.9062\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.4766, val loss: 5.4502\n",
      "epoch 31/10000 (batch 5000) - train loss: 4.9065, val loss: 4.8690\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.2134, val loss: 4.1606\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.4065, val loss: 3.3331\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.4557, val loss: 2.4473\n",
      "epoch 56/10000 (batch 9000) - train loss: 1.6500, val loss: 1.6389\n",
      "epoch 62/10000 (batch 10000) - train loss: 1.1102, val loss: 1.0986\n",
      "epoch 68/10000 (batch 11000) - train loss: 0.8524, val loss: 0.8366\n",
      "epoch 74/10000 (batch 12000) - train loss: 0.7359, val loss: 0.7330\n",
      "epoch 80/10000 (batch 13000) - train loss: 0.6852, val loss: 0.6879\n",
      "epoch 86/10000 (batch 14000) - train loss: 0.6560, val loss: 0.6556\n",
      "epoch 93/10000 (batch 15000) - train loss: 0.6658, val loss: 0.6429\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.6236, val loss: 0.6247\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.6011, val loss: 0.6072\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.5956, val loss: 0.5856\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.5725, val loss: 0.5620\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.5466, val loss: 0.5376\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.5197, val loss: 0.5136\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.4960, val loss: 0.4908\n",
      "epoch 142/10000 (batch 23000) - train loss: 0.4797, val loss: 0.4811\n",
      "epoch 148/10000 (batch 24000) - train loss: 0.4667, val loss: 0.4700\n",
      "epoch 154/10000 (batch 25000) - train loss: 0.4640, val loss: 0.4591\n",
      "epoch 160/10000 (batch 26000) - train loss: 0.4609, val loss: 0.4588\n",
      "epoch 166/10000 (batch 27000) - train loss: 0.4616, val loss: 0.4548\n",
      "epoch 172/10000 (batch 28000) - train loss: 0.4519, val loss: 0.4469\n",
      "epoch 178/10000 (batch 29000) - train loss: 0.4555, val loss: 0.4524\n",
      "Early stopping triggered at epoch 178, batch 29000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=263` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=122` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 7.0905, val loss: 7.1002\n",
      "epoch 2/10000 (batch 2000) - train loss: 7.0846, val loss: 7.0800\n",
      "epoch 2/10000 (batch 3000) - train loss: 7.0700, val loss: 7.0473\n",
      "epoch 3/10000 (batch 4000) - train loss: 7.0188, val loss: 7.0008\n",
      "epoch 4/10000 (batch 5000) - train loss: 6.9449, val loss: 6.9419\n",
      "epoch 4/10000 (batch 6000) - train loss: 6.9101, val loss: 6.8694\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.8050, val loss: 6.7843\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.7579, val loss: 6.6861\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.6217, val loss: 6.5749\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.4627, val loss: 6.4506\n",
      "epoch 7/10000 (batch 11000) - train loss: 6.3957, val loss: 6.3133\n",
      "epoch 8/10000 (batch 12000) - train loss: 6.2057, val loss: 6.1634\n",
      "epoch 8/10000 (batch 13000) - train loss: 6.1265, val loss: 6.0000\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.9060, val loss: 5.8242\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.6621, val loss: 5.6351\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.5629, val loss: 5.4319\n",
      "epoch 11/10000 (batch 17000) - train loss: 5.2887, val loss: 5.2176\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.9985, val loss: 4.9892\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.8713, val loss: 4.7484\n",
      "epoch 13/10000 (batch 20000) - train loss: 4.5433, val loss: 4.4939\n",
      "epoch 13/10000 (batch 21000) - train loss: 4.4127, val loss: 4.2298\n",
      "epoch 14/10000 (batch 22000) - train loss: 4.0590, val loss: 3.9536\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.6841, val loss: 3.6674\n",
      "epoch 15/10000 (batch 24000) - train loss: 3.5340, val loss: 3.3708\n",
      "epoch 16/10000 (batch 25000) - train loss: 3.1385, val loss: 3.0663\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.9857, val loss: 2.7591\n",
      "epoch 17/10000 (batch 27000) - train loss: 2.5805, val loss: 2.4522\n",
      "epoch 18/10000 (batch 28000) - train loss: 2.1844, val loss: 2.1526\n",
      "epoch 18/10000 (batch 29000) - train loss: 2.0390, val loss: 1.8672\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.6792, val loss: 1.6087\n",
      "epoch 19/10000 (batch 31000) - train loss: 1.5579, val loss: 1.3746\n",
      "epoch 20/10000 (batch 32000) - train loss: 1.2732, val loss: 1.1851\n",
      "epoch 21/10000 (batch 33000) - train loss: 1.0556, val loss: 1.0311\n",
      "epoch 21/10000 (batch 34000) - train loss: 0.9918, val loss: 0.9140\n",
      "epoch 22/10000 (batch 35000) - train loss: 0.8598, val loss: 0.8295\n",
      "epoch 23/10000 (batch 36000) - train loss: 0.7882, val loss: 0.7687\n",
      "epoch 23/10000 (batch 37000) - train loss: 0.7495, val loss: 0.7267\n",
      "epoch 24/10000 (batch 38000) - train loss: 0.7040, val loss: 0.6968\n",
      "epoch 24/10000 (batch 39000) - train loss: 0.6962, val loss: 0.6806\n",
      "epoch 25/10000 (batch 40000) - train loss: 0.6737, val loss: 0.6646\n",
      "epoch 26/10000 (batch 41000) - train loss: 0.6561, val loss: 0.6510\n",
      "epoch 26/10000 (batch 42000) - train loss: 0.6531, val loss: 0.6458\n",
      "epoch 27/10000 (batch 43000) - train loss: 0.6432, val loss: 0.6388\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.6413, val loss: 0.6297\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.6352, val loss: 0.6233\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.6256, val loss: 0.6217\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.6237, val loss: 0.6126\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.6152, val loss: 0.6105\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.6130, val loss: 0.6039\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.6061, val loss: 0.5975\n",
      "epoch 32/10000 (batch 51000) - train loss: 0.5942, val loss: 0.5949\n",
      "epoch 32/10000 (batch 52000) - train loss: 0.5945, val loss: 0.5863\n",
      "epoch 33/10000 (batch 53000) - train loss: 0.5880, val loss: 0.5791\n",
      "epoch 34/10000 (batch 54000) - train loss: 0.6004, val loss: 0.5735\n",
      "epoch 34/10000 (batch 55000) - train loss: 0.5750, val loss: 0.5663\n",
      "epoch 35/10000 (batch 56000) - train loss: 0.5625, val loss: 0.5585\n",
      "epoch 35/10000 (batch 57000) - train loss: 0.5611, val loss: 0.5542\n",
      "epoch 36/10000 (batch 58000) - train loss: 0.5523, val loss: 0.5447\n",
      "epoch 37/10000 (batch 59000) - train loss: 0.5443, val loss: 0.5384\n",
      "epoch 37/10000 (batch 60000) - train loss: 0.5393, val loss: 0.5295\n",
      "epoch 38/10000 (batch 61000) - train loss: 0.5289, val loss: 0.5229\n",
      "epoch 38/10000 (batch 62000) - train loss: 0.5244, val loss: 0.5146\n",
      "epoch 39/10000 (batch 63000) - train loss: 0.5143, val loss: 0.5083\n",
      "epoch 40/10000 (batch 64000) - train loss: 0.5037, val loss: 0.5003\n",
      "epoch 40/10000 (batch 65000) - train loss: 0.5022, val loss: 0.4927\n",
      "epoch 41/10000 (batch 66000) - train loss: 0.4958, val loss: 0.4883\n",
      "epoch 41/10000 (batch 67000) - train loss: 0.4921, val loss: 0.4845\n",
      "epoch 42/10000 (batch 68000) - train loss: 0.4824, val loss: 0.4778\n",
      "epoch 43/10000 (batch 69000) - train loss: 0.4794, val loss: 0.4735\n",
      "epoch 43/10000 (batch 70000) - train loss: 0.4765, val loss: 0.4700\n",
      "epoch 44/10000 (batch 71000) - train loss: 0.4701, val loss: 0.4632\n",
      "epoch 45/10000 (batch 72000) - train loss: 0.4686, val loss: 0.4619\n",
      "epoch 45/10000 (batch 73000) - train loss: 0.4657, val loss: 0.4587\n",
      "epoch 46/10000 (batch 74000) - train loss: 0.4633, val loss: 0.4591\n",
      "Early stopping triggered at epoch 46, batch 74000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a63b7880694a1abb3b6c351f934af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 287.209. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 1.1091, val loss: 1.2426\n",
      "epoch 2000/10000 (batch 2000) - train loss: 0.8370, val loss: 1.0249\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.7676, val loss: 0.9151\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.7233, val loss: 0.9302\n",
      "Early stopping triggered at epoch 4000, batch 4000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 276.016. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 324.335. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 284.917. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 6.1877, val loss: 6.1606\n",
      "epoch 125/10000 (batch 2000) - train loss: 4.2485, val loss: 4.2489\n",
      "epoch 188/10000 (batch 3000) - train loss: 1.6778, val loss: 1.7864\n",
      "epoch 250/10000 (batch 4000) - train loss: 1.0881, val loss: 1.1482\n",
      "epoch 313/10000 (batch 5000) - train loss: 1.0034, val loss: 1.0816\n",
      "epoch 375/10000 (batch 6000) - train loss: 0.9500, val loss: 1.0299\n",
      "epoch 438/10000 (batch 7000) - train loss: 0.9111, val loss: 0.9633\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.8092, val loss: 0.8954\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.7938, val loss: 0.8021\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.7542, val loss: 0.7994\n",
      "epoch 688/10000 (batch 11000) - train loss: 0.7405, val loss: 0.7677\n",
      "epoch 750/10000 (batch 12000) - train loss: 0.7332, val loss: 0.8242\n",
      "Early stopping triggered at epoch 750, batch 12000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 268.412. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.8743, val loss: 6.8752\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.6875, val loss: 6.6818\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.3797, val loss: 6.3681\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.9494, val loss: 5.9283\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.3960, val loss: 5.3639\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.7178, val loss: 4.6709\n",
      "epoch 43/10000 (batch 7000) - train loss: 3.9211, val loss: 3.8649\n",
      "epoch 50/10000 (batch 8000) - train loss: 2.9650, val loss: 2.9652\n",
      "epoch 56/10000 (batch 9000) - train loss: 2.1039, val loss: 2.1129\n",
      "epoch 62/10000 (batch 10000) - train loss: 1.5016, val loss: 1.5072\n",
      "epoch 68/10000 (batch 11000) - train loss: 1.2095, val loss: 1.2316\n",
      "epoch 74/10000 (batch 12000) - train loss: 1.1014, val loss: 1.1108\n",
      "epoch 80/10000 (batch 13000) - train loss: 1.0517, val loss: 1.0602\n",
      "epoch 86/10000 (batch 14000) - train loss: 1.0185, val loss: 1.0204\n",
      "epoch 93/10000 (batch 15000) - train loss: 1.0164, val loss: 1.0145\n",
      "epoch 99/10000 (batch 16000) - train loss: 0.9778, val loss: 0.9934\n",
      "epoch 105/10000 (batch 17000) - train loss: 0.9479, val loss: 0.9604\n",
      "epoch 111/10000 (batch 18000) - train loss: 0.9363, val loss: 0.9404\n",
      "epoch 117/10000 (batch 19000) - train loss: 0.8941, val loss: 0.9151\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.8669, val loss: 0.8795\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.8388, val loss: 0.8504\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.8126, val loss: 0.8300\n",
      "epoch 142/10000 (batch 23000) - train loss: 0.7880, val loss: 0.8091\n",
      "epoch 148/10000 (batch 24000) - train loss: 0.7742, val loss: 0.7985\n",
      "epoch 154/10000 (batch 25000) - train loss: 0.7726, val loss: 0.7780\n",
      "epoch 160/10000 (batch 26000) - train loss: 0.7675, val loss: 0.7785\n",
      "Early stopping triggered at epoch 160, batch 26000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=263` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=122` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.1923, val loss: 6.1553\n",
      "epoch 2/10000 (batch 2000) - train loss: 6.1407, val loss: 6.1359\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.1273, val loss: 6.1051\n",
      "epoch 3/10000 (batch 4000) - train loss: 6.0796, val loss: 6.0619\n",
      "epoch 4/10000 (batch 5000) - train loss: 6.0115, val loss: 6.0074\n",
      "epoch 4/10000 (batch 6000) - train loss: 5.9783, val loss: 5.9406\n",
      "epoch 5/10000 (batch 7000) - train loss: 5.8802, val loss: 5.8612\n",
      "epoch 5/10000 (batch 8000) - train loss: 5.8363, val loss: 5.7693\n",
      "epoch 6/10000 (batch 9000) - train loss: 5.7100, val loss: 5.6665\n",
      "epoch 7/10000 (batch 10000) - train loss: 5.5642, val loss: 5.5507\n",
      "epoch 7/10000 (batch 11000) - train loss: 5.4995, val loss: 5.4228\n",
      "epoch 8/10000 (batch 12000) - train loss: 5.3236, val loss: 5.2838\n",
      "epoch 8/10000 (batch 13000) - train loss: 5.2497, val loss: 5.1322\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.0445, val loss: 4.9685\n",
      "epoch 10/10000 (batch 15000) - train loss: 4.8175, val loss: 4.7927\n",
      "epoch 10/10000 (batch 16000) - train loss: 4.7261, val loss: 4.6059\n",
      "epoch 11/10000 (batch 17000) - train loss: 4.4721, val loss: 4.4071\n",
      "epoch 12/10000 (batch 18000) - train loss: 4.2074, val loss: 4.1971\n",
      "epoch 12/10000 (batch 19000) - train loss: 4.0886, val loss: 3.9743\n",
      "epoch 13/10000 (batch 20000) - train loss: 3.7884, val loss: 3.7429\n",
      "epoch 13/10000 (batch 21000) - train loss: 3.6689, val loss: 3.5033\n",
      "epoch 14/10000 (batch 22000) - train loss: 3.3502, val loss: 3.2563\n",
      "epoch 15/10000 (batch 23000) - train loss: 3.0203, val loss: 3.0031\n",
      "epoch 15/10000 (batch 24000) - train loss: 2.8865, val loss: 2.7467\n",
      "epoch 16/10000 (batch 25000) - train loss: 2.5524, val loss: 2.4920\n",
      "epoch 16/10000 (batch 26000) - train loss: 2.4268, val loss: 2.2436\n",
      "epoch 17/10000 (batch 27000) - train loss: 2.1086, val loss: 2.0107\n",
      "epoch 18/10000 (batch 28000) - train loss: 1.8196, val loss: 1.7996\n",
      "epoch 18/10000 (batch 29000) - train loss: 1.7217, val loss: 1.6117\n",
      "epoch 19/10000 (batch 30000) - train loss: 1.4971, val loss: 1.4589\n",
      "epoch 19/10000 (batch 31000) - train loss: 1.4323, val loss: 1.3357\n",
      "epoch 20/10000 (batch 32000) - train loss: 1.2849, val loss: 1.2432\n",
      "epoch 21/10000 (batch 33000) - train loss: 1.1799, val loss: 1.1734\n",
      "epoch 21/10000 (batch 34000) - train loss: 1.1557, val loss: 1.1233\n",
      "epoch 22/10000 (batch 35000) - train loss: 1.1053, val loss: 1.0918\n",
      "epoch 23/10000 (batch 36000) - train loss: 1.0723, val loss: 1.0688\n",
      "epoch 23/10000 (batch 37000) - train loss: 1.0605, val loss: 1.0496\n",
      "epoch 24/10000 (batch 38000) - train loss: 1.0514, val loss: 1.0423\n",
      "epoch 24/10000 (batch 39000) - train loss: 1.0369, val loss: 1.0334\n",
      "epoch 25/10000 (batch 40000) - train loss: 1.0247, val loss: 1.0202\n",
      "epoch 26/10000 (batch 41000) - train loss: 1.0085, val loss: 1.0156\n",
      "epoch 26/10000 (batch 42000) - train loss: 1.0107, val loss: 1.0058\n",
      "epoch 27/10000 (batch 43000) - train loss: 1.0039, val loss: 1.0022\n",
      "epoch 27/10000 (batch 44000) - train loss: 0.9994, val loss: 0.9923\n",
      "epoch 28/10000 (batch 45000) - train loss: 0.9898, val loss: 0.9855\n",
      "epoch 29/10000 (batch 46000) - train loss: 0.9831, val loss: 0.9784\n",
      "epoch 29/10000 (batch 47000) - train loss: 0.9765, val loss: 0.9706\n",
      "epoch 30/10000 (batch 48000) - train loss: 0.9670, val loss: 0.9618\n",
      "epoch 30/10000 (batch 49000) - train loss: 0.9627, val loss: 0.9576\n",
      "epoch 31/10000 (batch 50000) - train loss: 0.9551, val loss: 0.9452\n",
      "epoch 32/10000 (batch 51000) - train loss: 0.9394, val loss: 0.9411\n",
      "epoch 32/10000 (batch 52000) - train loss: 0.9394, val loss: 0.9337\n",
      "epoch 33/10000 (batch 53000) - train loss: 0.9259, val loss: 0.9205\n",
      "epoch 34/10000 (batch 54000) - train loss: 0.9204, val loss: 0.9158\n",
      "epoch 34/10000 (batch 55000) - train loss: 0.9099, val loss: 0.9037\n",
      "epoch 35/10000 (batch 56000) - train loss: 0.8987, val loss: 0.8968\n",
      "epoch 35/10000 (batch 57000) - train loss: 0.8947, val loss: 0.8886\n",
      "epoch 36/10000 (batch 58000) - train loss: 0.8822, val loss: 0.8761\n",
      "epoch 37/10000 (batch 59000) - train loss: 0.8694, val loss: 0.8673\n",
      "epoch 37/10000 (batch 60000) - train loss: 0.8632, val loss: 0.8579\n",
      "epoch 38/10000 (batch 61000) - train loss: 0.8597, val loss: 0.8483\n",
      "epoch 38/10000 (batch 62000) - train loss: 0.8491, val loss: 0.8390\n",
      "epoch 39/10000 (batch 63000) - train loss: 0.8356, val loss: 0.8342\n",
      "epoch 40/10000 (batch 64000) - train loss: 0.8179, val loss: 0.8231\n",
      "epoch 40/10000 (batch 65000) - train loss: 0.8206, val loss: 0.8141\n",
      "epoch 41/10000 (batch 66000) - train loss: 0.8072, val loss: 0.8072\n",
      "epoch 41/10000 (batch 67000) - train loss: 0.8082, val loss: 0.8023\n",
      "epoch 42/10000 (batch 68000) - train loss: 0.7975, val loss: 0.7944\n",
      "epoch 43/10000 (batch 69000) - train loss: 0.7918, val loss: 0.7887\n",
      "epoch 43/10000 (batch 70000) - train loss: 0.7900, val loss: 0.7840\n",
      "epoch 44/10000 (batch 71000) - train loss: 0.7816, val loss: 0.7807\n",
      "epoch 45/10000 (batch 72000) - train loss: 0.7899, val loss: 0.7756\n",
      "epoch 45/10000 (batch 73000) - train loss: 0.7752, val loss: 0.7710\n",
      "epoch 46/10000 (batch 74000) - train loss: 0.7752, val loss: 0.7699\n",
      "epoch 46/10000 (batch 75000) - train loss: 0.7718, val loss: 0.7673\n",
      "epoch 47/10000 (batch 76000) - train loss: 0.7678, val loss: 0.7667\n",
      "epoch 48/10000 (batch 77000) - train loss: 0.7714, val loss: 0.7639\n",
      "epoch 48/10000 (batch 78000) - train loss: 0.7646, val loss: 0.7595\n",
      "epoch 49/10000 (batch 79000) - train loss: 0.7582, val loss: 0.7587\n",
      "epoch 49/10000 (batch 80000) - train loss: 0.7606, val loss: 0.7559\n",
      "epoch 50/10000 (batch 81000) - train loss: 0.7588, val loss: 0.7566\n",
      "Early stopping triggered at epoch 50, batch 81000\n",
      "embedding generation completed! :) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe66bfe1b9c45919713066d339a3271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/home/gokul/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "fractions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 334.626. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1000/10000 (batch 1000) - train loss: 1.2799, val loss: 1.2249\n",
      "epoch 2000/10000 (batch 2000) - train loss: 1.0277, val loss: 1.0279\n",
      "epoch 3000/10000 (batch 3000) - train loss: 0.9629, val loss: 0.9263\n",
      "epoch 4000/10000 (batch 4000) - train loss: 0.9226, val loss: 0.8114\n",
      "epoch 5000/10000 (batch 5000) - train loss: 0.8680, val loss: 0.8689\n",
      "Early stopping triggered at epoch 5000, batch 5000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 350.199. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 382.706. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 375.405. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 63/10000 (batch 1000) - train loss: 6.1311, val loss: 6.0881\n",
      "epoch 125/10000 (batch 2000) - train loss: 4.2653, val loss: 4.2591\n",
      "epoch 188/10000 (batch 3000) - train loss: 1.8019, val loss: 1.8478\n",
      "epoch 250/10000 (batch 4000) - train loss: 1.2067, val loss: 1.2214\n",
      "epoch 313/10000 (batch 5000) - train loss: 1.1413, val loss: 1.1510\n",
      "epoch 375/10000 (batch 6000) - train loss: 1.0708, val loss: 1.1195\n",
      "epoch 438/10000 (batch 7000) - train loss: 1.0137, val loss: 1.0342\n",
      "epoch 500/10000 (batch 8000) - train loss: 0.9168, val loss: 0.9521\n",
      "epoch 563/10000 (batch 9000) - train loss: 0.8875, val loss: 0.8790\n",
      "epoch 625/10000 (batch 10000) - train loss: 0.8684, val loss: 0.8984\n",
      "Early stopping triggered at epoch 625, batch 10000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 342.468. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/gokul/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 7/10000 (batch 1000) - train loss: 6.7688, val loss: 6.7668\n",
      "epoch 13/10000 (batch 2000) - train loss: 6.5945, val loss: 6.5897\n",
      "epoch 19/10000 (batch 3000) - train loss: 6.3099, val loss: 6.2997\n",
      "epoch 25/10000 (batch 4000) - train loss: 5.9157, val loss: 5.8967\n",
      "epoch 31/10000 (batch 5000) - train loss: 5.4087, val loss: 5.3791\n",
      "epoch 37/10000 (batch 6000) - train loss: 4.7905, val loss: 4.7470\n",
      "epoch 43/10000 (batch 7000) - train loss: 4.0641, val loss: 4.0030\n",
      "epoch 50/10000 (batch 8000) - train loss: 3.1633, val loss: 3.1822\n",
      "epoch 56/10000 (batch 9000) - train loss: 2.3390, val loss: 2.3528\n",
      "epoch 62/10000 (batch 10000) - train loss: 1.7170, val loss: 1.7203\n",
      "epoch 68/10000 (batch 11000) - train loss: 1.3889, val loss: 1.3871\n",
      "epoch 74/10000 (batch 12000) - train loss: 1.2541, val loss: 1.2608\n",
      "epoch 80/10000 (batch 13000) - train loss: 1.1914, val loss: 1.2067\n",
      "epoch 86/10000 (batch 14000) - train loss: 1.1554, val loss: 1.1613\n",
      "epoch 93/10000 (batch 15000) - train loss: 1.1452, val loss: 1.1346\n",
      "epoch 99/10000 (batch 16000) - train loss: 1.1195, val loss: 1.0989\n",
      "epoch 105/10000 (batch 17000) - train loss: 1.0777, val loss: 1.0877\n",
      "epoch 111/10000 (batch 18000) - train loss: 1.0394, val loss: 1.0454\n",
      "epoch 117/10000 (batch 19000) - train loss: 1.0014, val loss: 1.0131\n",
      "epoch 123/10000 (batch 20000) - train loss: 0.9756, val loss: 0.9820\n",
      "epoch 129/10000 (batch 21000) - train loss: 0.9413, val loss: 0.9521\n",
      "epoch 135/10000 (batch 22000) - train loss: 0.9200, val loss: 0.9302\n",
      "epoch 142/10000 (batch 23000) - train loss: 0.8926, val loss: 0.9081\n",
      "epoch 148/10000 (batch 24000) - train loss: 0.8897, val loss: 0.9040\n",
      "epoch 154/10000 (batch 25000) - train loss: 0.8822, val loss: 0.8914\n",
      "epoch 160/10000 (batch 26000) - train loss: 0.8771, val loss: 0.8800\n",
      "epoch 166/10000 (batch 27000) - train loss: 0.8739, val loss: 0.8842\n",
      "Early stopping triggered at epoch 166, batch 27000\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 313.870. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=263` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=122` reached.\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData\n",
      "         setup                                                                  \n",
      "epoch 1/10000 (batch 1000) - train loss: 6.9894, val loss: 6.9915\n",
      "epoch 2/10000 (batch 2000) - train loss: 6.9778, val loss: 6.9736\n",
      "epoch 2/10000 (batch 3000) - train loss: 6.9650, val loss: 6.9449\n",
      "epoch 3/10000 (batch 4000) - train loss: 6.9209, val loss: 6.9048\n",
      "epoch 4/10000 (batch 5000) - train loss: 6.8567, val loss: 6.8539\n",
      "epoch 4/10000 (batch 6000) - train loss: 6.8264, val loss: 6.7912\n",
      "epoch 5/10000 (batch 7000) - train loss: 6.7354, val loss: 6.7176\n",
      "epoch 5/10000 (batch 8000) - train loss: 6.6943, val loss: 6.6324\n",
      "epoch 6/10000 (batch 9000) - train loss: 6.5766, val loss: 6.5362\n",
      "epoch 7/10000 (batch 10000) - train loss: 6.4387, val loss: 6.4287\n",
      "epoch 7/10000 (batch 11000) - train loss: 6.3809, val loss: 6.3100\n",
      "epoch 8/10000 (batch 12000) - train loss: 6.2161, val loss: 6.1796\n",
      "epoch 8/10000 (batch 13000) - train loss: 6.1478, val loss: 6.0381\n",
      "epoch 9/10000 (batch 14000) - train loss: 5.9566, val loss: 5.8862\n",
      "epoch 10/10000 (batch 15000) - train loss: 5.7456, val loss: 5.7223\n",
      "epoch 10/10000 (batch 16000) - train loss: 5.6596, val loss: 5.5469\n",
      "epoch 11/10000 (batch 17000) - train loss: 5.4217, val loss: 5.3607\n",
      "epoch 12/10000 (batch 18000) - train loss: 5.1657, val loss: 5.1630\n",
      "epoch 12/10000 (batch 19000) - train loss: 5.0602, val loss: 4.9544\n",
      "epoch 13/10000 (batch 20000) - train loss: 4.7748, val loss: 4.7340\n",
      "epoch 13/10000 (batch 21000) - train loss: 4.6607, val loss: 4.5009\n",
      "epoch 14/10000 (batch 22000) - train loss: 4.3494, val loss: 4.2583\n",
      "epoch 15/10000 (batch 23000) - train loss: 4.0220, val loss: 4.0063\n",
      "epoch 15/10000 (batch 24000) - train loss: 3.8896, val loss: 3.7450\n",
      "epoch 16/10000 (batch 25000) - train loss: 3.5383, val loss: 3.4771\n",
      "epoch 16/10000 (batch 26000) - train loss: 3.4026, val loss: 3.2016\n",
      "epoch 17/10000 (batch 27000) - train loss: 3.0386, val loss: 2.9260\n",
      "epoch 18/10000 (batch 28000) - train loss: 2.6774, val loss: 2.6513\n",
      "epoch 18/10000 (batch 29000) - train loss: 2.5444, val loss: 2.3849\n",
      "epoch 19/10000 (batch 30000) - train loss: 2.2048, val loss: 2.1358\n",
      "epoch 19/10000 (batch 31000) - train loss: 2.0884, val loss: 1.9101\n",
      "epoch 20/10000 (batch 32000) - train loss: 1.8059, val loss: 1.7185\n",
      "epoch 21/10000 (batch 33000) - train loss: 1.5829, val loss: 1.5635\n",
      "epoch 21/10000 (batch 34000) - train loss: 1.5187, val loss: 1.4400\n",
      "epoch 22/10000 (batch 35000) - train loss: 1.3757, val loss: 1.3483\n",
      "epoch 23/10000 (batch 36000) - train loss: 1.2887, val loss: 1.2903\n",
      "epoch 23/10000 (batch 37000) - train loss: 1.2671, val loss: 1.2485\n",
      "epoch 24/10000 (batch 38000) - train loss: 1.2188, val loss: 1.2133\n",
      "epoch 24/10000 (batch 39000) - train loss: 1.2109, val loss: 1.1946\n",
      "epoch 25/10000 (batch 40000) - train loss: 1.1905, val loss: 1.1838\n",
      "epoch 26/10000 (batch 41000) - train loss: 1.1613, val loss: 1.1675\n",
      "epoch 26/10000 (batch 42000) - train loss: 1.1631, val loss: 1.1584\n",
      "epoch 27/10000 (batch 43000) - train loss: 1.1503, val loss: 1.1467\n",
      "epoch 27/10000 (batch 44000) - train loss: 1.1484, val loss: 1.1418\n",
      "epoch 28/10000 (batch 45000) - train loss: 1.1380, val loss: 1.1333\n",
      "epoch 29/10000 (batch 46000) - train loss: 1.1298, val loss: 1.1236\n",
      "epoch 29/10000 (batch 47000) - train loss: 1.1231, val loss: 1.1170\n",
      "epoch 30/10000 (batch 48000) - train loss: 1.1108, val loss: 1.1082\n",
      "epoch 30/10000 (batch 49000) - train loss: 1.1065, val loss: 1.0958\n",
      "epoch 31/10000 (batch 50000) - train loss: 1.0919, val loss: 1.0933\n",
      "epoch 32/10000 (batch 51000) - train loss: 1.0822, val loss: 1.0789\n",
      "epoch 32/10000 (batch 52000) - train loss: 1.0780, val loss: 1.0716\n",
      "epoch 33/10000 (batch 53000) - train loss: 1.0658, val loss: 1.0606\n",
      "epoch 34/10000 (batch 54000) - train loss: 1.0349, val loss: 1.0489\n",
      "epoch 34/10000 (batch 55000) - train loss: 1.0492, val loss: 1.0392\n",
      "epoch 35/10000 (batch 56000) - train loss: 1.0350, val loss: 1.0253\n",
      "epoch 35/10000 (batch 57000) - train loss: 1.0267, val loss: 1.0160\n",
      "epoch 36/10000 (batch 58000) - train loss: 1.0107, val loss: 1.0103\n",
      "epoch 37/10000 (batch 59000) - train loss: 0.9960, val loss: 0.9966\n",
      "epoch 37/10000 (batch 60000) - train loss: 0.9950, val loss: 0.9871\n",
      "epoch 38/10000 (batch 61000) - train loss: 0.9808, val loss: 0.9748\n",
      "epoch 38/10000 (batch 62000) - train loss: 0.9752, val loss: 0.9649\n",
      "epoch 39/10000 (batch 63000) - train loss: 0.9625, val loss: 0.9559\n",
      "epoch 40/10000 (batch 64000) - train loss: 0.9421, val loss: 0.9471\n",
      "epoch 40/10000 (batch 65000) - train loss: 0.9444, val loss: 0.9405\n",
      "epoch 41/10000 (batch 66000) - train loss: 0.9364, val loss: 0.9311\n",
      "epoch 41/10000 (batch 67000) - train loss: 0.9316, val loss: 0.9239\n",
      "epoch 42/10000 (batch 68000) - train loss: 0.9226, val loss: 0.9174\n",
      "epoch 43/10000 (batch 69000) - train loss: 0.9063, val loss: 0.9124\n",
      "epoch 43/10000 (batch 70000) - train loss: 0.9094, val loss: 0.9056\n",
      "epoch 44/10000 (batch 71000) - train loss: 0.9041, val loss: 0.9021\n",
      "epoch 45/10000 (batch 72000) - train loss: 0.9260, val loss: 0.8978\n",
      "epoch 45/10000 (batch 73000) - train loss: 0.8964, val loss: 0.8953\n",
      "epoch 46/10000 (batch 74000) - train loss: 0.8915, val loss: 0.8899\n",
      "epoch 46/10000 (batch 75000) - train loss: 0.8904, val loss: 0.8882\n",
      "epoch 47/10000 (batch 76000) - train loss: 0.8846, val loss: 0.8845\n",
      "epoch 48/10000 (batch 77000) - train loss: 0.8876, val loss: 0.8851\n",
      "Early stopping triggered at epoch 48, batch 77000\n",
      "embedding generation completed! :) \n"
     ]
    }
   ],
   "source": [
    "for q in tqdm(qualities):\n",
    "    for r in tqdm(range(replicates), leave=False):\n",
    "        # with io.capture_output() as captured:\n",
    "        !python LARRY_embedding_generation.py {q} {r} 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
